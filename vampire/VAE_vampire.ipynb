{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import VAE_vampire\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sonnia.processing import Processing\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDR3</th>\n",
       "      <th>CDR3_al</th>\n",
       "      <th>tokenized_smiles</th>\n",
       "      <th>TCR BioIdentity</th>\n",
       "      <th>TCR Nucleotide Sequence</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>ORF Coverage</th>\n",
       "      <th>Amino Acids</th>\n",
       "      <th>Start Index in Genome</th>\n",
       "      <th>End Index in Genome</th>\n",
       "      <th>v_gene</th>\n",
       "      <th>j_gene</th>\n",
       "      <th>Amino Acids 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASSAQGTGDRGYTF</td>\n",
       "      <td>CASSA-----QGTGDRGYTF</td>\n",
       "      <td>[12, 16, 34, 34, 31, 31, 31, 31, 31, 27, 13]</td>\n",
       "      <td>CASSAQGTGDRGYTF+TCRBV27-01+TCRBJ01-02</td>\n",
       "      <td>GAGTCGCCCAGCCCCAACCAGACCTCTCTGTACTTCTGTGCCAGCA...</td>\n",
       "      <td>eAV93</td>\n",
       "      <td>ORF1ab,surface glycoprotein</td>\n",
       "      <td>ADAGFIKQY,AELEGIQY,LADAGFIKQY,TLADAGFIK</td>\n",
       "      <td>533</td>\n",
       "      <td>24073</td>\n",
       "      <td>TCRBV27-01</td>\n",
       "      <td>TCRBJ01-02</td>\n",
       "      <td>ADAGFIKQY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASSLVATGNTGELFF</td>\n",
       "      <td>CASSL----VATGNTGELFF</td>\n",
       "      <td>[12, 16, 34, 34, 31, 31, 31, 31, 23, 27, 27, 13]</td>\n",
       "      <td>CASSLVATGNTGELFF+TCRBV07-09+TCRBJ02-02</td>\n",
       "      <td>CGCACAGAGCAGGGGGACTCGGCCATGTATCTCTGTGCCAGCAGCT...</td>\n",
       "      <td>eOX56</td>\n",
       "      <td>ORF1ab,surface glycoprotein</td>\n",
       "      <td>ADAGFIKQY,AELEGIQY,LADAGFIKQY,TLADAGFIK</td>\n",
       "      <td>533</td>\n",
       "      <td>24073</td>\n",
       "      <td>TCRBV07-09</td>\n",
       "      <td>TCRBJ02-02</td>\n",
       "      <td>ADAGFIKQY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALKVGADTQYF</td>\n",
       "      <td>CALKV--------GADTQYF</td>\n",
       "      <td>[12, 16, 31, 31, 31, 31, 31, 31, 31, 31, 27, 13]</td>\n",
       "      <td>CALKVGADTQYF+TCRBV30-01+TCRBJ02-03</td>\n",
       "      <td>CTGAGTTCTAAGAAGCTCCTTCTCAGTGACTCTGGCTTCTATCTCT...</td>\n",
       "      <td>eQD124</td>\n",
       "      <td>ORF1ab,surface glycoprotein</td>\n",
       "      <td>ADAGFIKQY,AELEGIQY,LADAGFIKQY,TLADAGFIK</td>\n",
       "      <td>533</td>\n",
       "      <td>24073</td>\n",
       "      <td>TCRBV30-01</td>\n",
       "      <td>TCRBJ02-03</td>\n",
       "      <td>ADAGFIKQY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CASSLWASGRGGTGELFF</td>\n",
       "      <td>CASSLW--ASGRGGTGELFF</td>\n",
       "      <td>[12, 16, 34, 34, 31, 31, 34, 27, 27, 13]</td>\n",
       "      <td>CASSLWASGRGGTGELFF+TCRBV27-01+TCRBJ02-02</td>\n",
       "      <td>AGCCCCAACCAGACCTCTCTGTACTTCTGTGCCAGCAGTTTATGGG...</td>\n",
       "      <td>eAV93</td>\n",
       "      <td>ORF1ab,surface glycoprotein</td>\n",
       "      <td>ADAGFIKQY,AELEGIQY,LADAGFIKQY,TLADAGFIK</td>\n",
       "      <td>533</td>\n",
       "      <td>24073</td>\n",
       "      <td>TCRBV27-01</td>\n",
       "      <td>TCRBJ02-02</td>\n",
       "      <td>ADAGFIKQY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CASSLLGWEQLDEQFF</td>\n",
       "      <td>CASSL----LGWEQLDEQFF</td>\n",
       "      <td>[12, 16, 34, 34, 31, 31, 31, 31, 27, 27, 13]</td>\n",
       "      <td>CASSLLGWEQLDEQFF+TCRBV27-01+TCRBJ02-01</td>\n",
       "      <td>TCGCCCAGCCCCAACCAGACCTCTCTGTACTTCTGTGCCAGCAGTT...</td>\n",
       "      <td>eMR16</td>\n",
       "      <td>ORF1ab,surface glycoprotein</td>\n",
       "      <td>ADAGFIKQY,AELEGIQY,LADAGFIKQY,TLADAGFIK</td>\n",
       "      <td>533</td>\n",
       "      <td>24073</td>\n",
       "      <td>TCRBV27-01</td>\n",
       "      <td>TCRBJ02-01</td>\n",
       "      <td>ADAGFIKQY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236340</th>\n",
       "      <td>CASSSGPQETQYF</td>\n",
       "      <td>CASSS-------GPQETQYF</td>\n",
       "      <td>[12, 16, 34, 34, 34, 31, 31, 31, 31, 31, 31, 3...</td>\n",
       "      <td>CASSSGPQETQYF+TCRBV07-09+TCRBJ02-05</td>\n",
       "      <td>GAGATCCAGCGCACAGAGCAGGGGGACTCGGCCATGTATCTCTGTG...</td>\n",
       "      <td>eAV88</td>\n",
       "      <td>ORF10</td>\n",
       "      <td>AQVDVVNFNL,NYIAQVDVV</td>\n",
       "      <td>29630</td>\n",
       "      <td>29668</td>\n",
       "      <td>TCRBV07-09</td>\n",
       "      <td>TCRBJ02-05</td>\n",
       "      <td>AQVDVVNFNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236341</th>\n",
       "      <td>CASSKRDSQETQYF</td>\n",
       "      <td>CASSK------RDSQETQYF</td>\n",
       "      <td>[12, 16, 34, 34, 31, 31, 31, 31, 31, 31, 34, 2...</td>\n",
       "      <td>CASSKRDSQETQYF+TCRBV07-09+TCRBJ02-05</td>\n",
       "      <td>ATCCAGCGCACAGAGCAGGGGGACTCGGCCATGTATCTCTGTGCCA...</td>\n",
       "      <td>eDH105</td>\n",
       "      <td>ORF10</td>\n",
       "      <td>AQVDVVNFNL,NYIAQVDVV</td>\n",
       "      <td>29630</td>\n",
       "      <td>29668</td>\n",
       "      <td>TCRBV07-09</td>\n",
       "      <td>TCRBJ02-05</td>\n",
       "      <td>AQVDVVNFNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236342</th>\n",
       "      <td>CASSQLPGQGKVQYF</td>\n",
       "      <td>CASSQ-----LPGQGKVQYF</td>\n",
       "      <td>[12, 16, 34, 34, 31, 31, 31, 31, 31, 45, 27, 13]</td>\n",
       "      <td>CASSQLPGQGKVQYF+TCRBV04-01+TCRBJ02-07</td>\n",
       "      <td>CACGCCCTGCAGCCAGAAGACTCAGCCCTGTATCTCTGCGCCAGCA...</td>\n",
       "      <td>eAV93</td>\n",
       "      <td>ORF10</td>\n",
       "      <td>AQVDVVNFNL,NYIAQVDVV</td>\n",
       "      <td>29630</td>\n",
       "      <td>29668</td>\n",
       "      <td>TCRBV04-01</td>\n",
       "      <td>TCRBJ02-07</td>\n",
       "      <td>AQVDVVNFNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236343</th>\n",
       "      <td>CASSPGDNEQFF</td>\n",
       "      <td>CASSP--------GDNEQFF</td>\n",
       "      <td>[12, 16, 34, 34, 45, 31, 31, 31, 31, 31, 31, 3...</td>\n",
       "      <td>CASSPGDNEQFF+TCRBV09-01+TCRBJ02-01</td>\n",
       "      <td>CTAAACCTGAGCTCTCTGGAGCTGGGGGACTCAGCTTTGTATTTCT...</td>\n",
       "      <td>eEE224</td>\n",
       "      <td>ORF10</td>\n",
       "      <td>AQVDVVNFNL,NYIAQVDVV</td>\n",
       "      <td>29630</td>\n",
       "      <td>29668</td>\n",
       "      <td>TCRBV09-01</td>\n",
       "      <td>TCRBJ02-01</td>\n",
       "      <td>AQVDVVNFNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236344</th>\n",
       "      <td>CASSVGDPDTQYF</td>\n",
       "      <td>CASSV-------GDPDTQYF</td>\n",
       "      <td>[12, 16, 34, 34, 31, 31, 31, 31, 31, 31, 31, 4...</td>\n",
       "      <td>CASSVGDPDTQYF+TCRBV09-01+TCRBJ02-03</td>\n",
       "      <td>AACCTGAGCTCTCTGGAGCTGGGGGACTCAGCTTTGTATTTCTGTG...</td>\n",
       "      <td>eAV88</td>\n",
       "      <td>ORF10</td>\n",
       "      <td>AQVDVVNFNL,NYIAQVDVV</td>\n",
       "      <td>29630</td>\n",
       "      <td>29668</td>\n",
       "      <td>TCRBV09-01</td>\n",
       "      <td>TCRBJ02-03</td>\n",
       "      <td>AQVDVVNFNL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236345 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      CDR3               CDR3_al  \\\n",
       "0          CASSAQGTGDRGYTF  CASSA-----QGTGDRGYTF   \n",
       "1         CASSLVATGNTGELFF  CASSL----VATGNTGELFF   \n",
       "2             CALKVGADTQYF  CALKV--------GADTQYF   \n",
       "3       CASSLWASGRGGTGELFF  CASSLW--ASGRGGTGELFF   \n",
       "4         CASSLLGWEQLDEQFF  CASSL----LGWEQLDEQFF   \n",
       "...                    ...                   ...   \n",
       "236340       CASSSGPQETQYF  CASSS-------GPQETQYF   \n",
       "236341      CASSKRDSQETQYF  CASSK------RDSQETQYF   \n",
       "236342     CASSQLPGQGKVQYF  CASSQ-----LPGQGKVQYF   \n",
       "236343        CASSPGDNEQFF  CASSP--------GDNEQFF   \n",
       "236344       CASSVGDPDTQYF  CASSV-------GDPDTQYF   \n",
       "\n",
       "                                         tokenized_smiles  \\\n",
       "0            [12, 16, 34, 34, 31, 31, 31, 31, 31, 27, 13]   \n",
       "1        [12, 16, 34, 34, 31, 31, 31, 31, 23, 27, 27, 13]   \n",
       "2        [12, 16, 31, 31, 31, 31, 31, 31, 31, 31, 27, 13]   \n",
       "3                [12, 16, 34, 34, 31, 31, 34, 27, 27, 13]   \n",
       "4            [12, 16, 34, 34, 31, 31, 31, 31, 27, 27, 13]   \n",
       "...                                                   ...   \n",
       "236340  [12, 16, 34, 34, 34, 31, 31, 31, 31, 31, 31, 3...   \n",
       "236341  [12, 16, 34, 34, 31, 31, 31, 31, 31, 31, 34, 2...   \n",
       "236342   [12, 16, 34, 34, 31, 31, 31, 31, 31, 45, 27, 13]   \n",
       "236343  [12, 16, 34, 34, 45, 31, 31, 31, 31, 31, 31, 3...   \n",
       "236344  [12, 16, 34, 34, 31, 31, 31, 31, 31, 31, 31, 4...   \n",
       "\n",
       "                                 TCR BioIdentity  \\\n",
       "0          CASSAQGTGDRGYTF+TCRBV27-01+TCRBJ01-02   \n",
       "1         CASSLVATGNTGELFF+TCRBV07-09+TCRBJ02-02   \n",
       "2             CALKVGADTQYF+TCRBV30-01+TCRBJ02-03   \n",
       "3       CASSLWASGRGGTGELFF+TCRBV27-01+TCRBJ02-02   \n",
       "4         CASSLLGWEQLDEQFF+TCRBV27-01+TCRBJ02-01   \n",
       "...                                          ...   \n",
       "236340       CASSSGPQETQYF+TCRBV07-09+TCRBJ02-05   \n",
       "236341      CASSKRDSQETQYF+TCRBV07-09+TCRBJ02-05   \n",
       "236342     CASSQLPGQGKVQYF+TCRBV04-01+TCRBJ02-07   \n",
       "236343        CASSPGDNEQFF+TCRBV09-01+TCRBJ02-01   \n",
       "236344       CASSVGDPDTQYF+TCRBV09-01+TCRBJ02-03   \n",
       "\n",
       "                                  TCR Nucleotide Sequence Experiment  \\\n",
       "0       GAGTCGCCCAGCCCCAACCAGACCTCTCTGTACTTCTGTGCCAGCA...      eAV93   \n",
       "1       CGCACAGAGCAGGGGGACTCGGCCATGTATCTCTGTGCCAGCAGCT...      eOX56   \n",
       "2       CTGAGTTCTAAGAAGCTCCTTCTCAGTGACTCTGGCTTCTATCTCT...     eQD124   \n",
       "3       AGCCCCAACCAGACCTCTCTGTACTTCTGTGCCAGCAGTTTATGGG...      eAV93   \n",
       "4       TCGCCCAGCCCCAACCAGACCTCTCTGTACTTCTGTGCCAGCAGTT...      eMR16   \n",
       "...                                                   ...        ...   \n",
       "236340  GAGATCCAGCGCACAGAGCAGGGGGACTCGGCCATGTATCTCTGTG...      eAV88   \n",
       "236341  ATCCAGCGCACAGAGCAGGGGGACTCGGCCATGTATCTCTGTGCCA...     eDH105   \n",
       "236342  CACGCCCTGCAGCCAGAAGACTCAGCCCTGTATCTCTGCGCCAGCA...      eAV93   \n",
       "236343  CTAAACCTGAGCTCTCTGGAGCTGGGGGACTCAGCTTTGTATTTCT...     eEE224   \n",
       "236344  AACCTGAGCTCTCTGGAGCTGGGGGACTCAGCTTTGTATTTCTGTG...      eAV88   \n",
       "\n",
       "                       ORF Coverage                              Amino Acids  \\\n",
       "0       ORF1ab,surface glycoprotein  ADAGFIKQY,AELEGIQY,LADAGFIKQY,TLADAGFIK   \n",
       "1       ORF1ab,surface glycoprotein  ADAGFIKQY,AELEGIQY,LADAGFIKQY,TLADAGFIK   \n",
       "2       ORF1ab,surface glycoprotein  ADAGFIKQY,AELEGIQY,LADAGFIKQY,TLADAGFIK   \n",
       "3       ORF1ab,surface glycoprotein  ADAGFIKQY,AELEGIQY,LADAGFIKQY,TLADAGFIK   \n",
       "4       ORF1ab,surface glycoprotein  ADAGFIKQY,AELEGIQY,LADAGFIKQY,TLADAGFIK   \n",
       "...                             ...                                      ...   \n",
       "236340                        ORF10                     AQVDVVNFNL,NYIAQVDVV   \n",
       "236341                        ORF10                     AQVDVVNFNL,NYIAQVDVV   \n",
       "236342                        ORF10                     AQVDVVNFNL,NYIAQVDVV   \n",
       "236343                        ORF10                     AQVDVVNFNL,NYIAQVDVV   \n",
       "236344                        ORF10                     AQVDVVNFNL,NYIAQVDVV   \n",
       "\n",
       "        Start Index in Genome  End Index in Genome      v_gene      j_gene  \\\n",
       "0                         533                24073  TCRBV27-01  TCRBJ01-02   \n",
       "1                         533                24073  TCRBV07-09  TCRBJ02-02   \n",
       "2                         533                24073  TCRBV30-01  TCRBJ02-03   \n",
       "3                         533                24073  TCRBV27-01  TCRBJ02-02   \n",
       "4                         533                24073  TCRBV27-01  TCRBJ02-01   \n",
       "...                       ...                  ...         ...         ...   \n",
       "236340                  29630                29668  TCRBV07-09  TCRBJ02-05   \n",
       "236341                  29630                29668  TCRBV07-09  TCRBJ02-05   \n",
       "236342                  29630                29668  TCRBV04-01  TCRBJ02-07   \n",
       "236343                  29630                29668  TCRBV09-01  TCRBJ02-01   \n",
       "236344                  29630                29668  TCRBV09-01  TCRBJ02-03   \n",
       "\n",
       "       Amino Acids 1  \n",
       "0          ADAGFIKQY  \n",
       "1          ADAGFIKQY  \n",
       "2          ADAGFIKQY  \n",
       "3          ADAGFIKQY  \n",
       "4          ADAGFIKQY  \n",
       "...              ...  \n",
       "236340    AQVDVVNFNL  \n",
       "236341    AQVDVVNFNL  \n",
       "236342    AQVDVVNFNL  \n",
       "236343    AQVDVVNFNL  \n",
       "236344    AQVDVVNFNL  \n",
       "\n",
       "[236345 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('peptide-detail-ci_filtered_aligned_merged.csv')\n",
    "df[\"Amino Acids 1\"] = df[\"Amino Acids\"].apply(lambda x: x.split(\",\")[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e26f9e2bcf43c080f06390d15cdb6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/236345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "aa = [\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\",\"R\", \"S\", \"T\", \"V\", \"W\", \"Y\", \"-\"]\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoder =LabelEncoder()\n",
    "y_encoder = y_encoder.fit(df['Amino Acids'].unique())\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = label_encoder.fit_transform(aa)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit(integer_encoded)\n",
    "\n",
    "one_hot_status = True\n",
    "col_one_hot = []\n",
    "col_integer = []\n",
    "y_labels = []\n",
    "for k in tqdm(df.index):\n",
    "    integer_encoded = label_encoder.transform(list(df.loc[k,\"CDR3_al\"]))\n",
    "    col_integer.append(integer_encoded)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    if one_hot_status:\n",
    "        onehot_encoded = onehot_encoder.transform(integer_encoded)\n",
    "        col_one_hot.append(onehot_encoded)\n",
    "    y_label = y_encoder.transform([df.loc[k,\"Amino Acids\"]])\n",
    "    y_labels.append(y_label)\n",
    "    \n",
    "y_labels = [int(y) for y in y_labels]\n",
    "if one_hot_status:\n",
    "    df[\"CDR3_al_one_hot\"] = col_one_hot\n",
    "df[\"CDR3_al_integer\"] = col_integer\n",
    "df[\"label\"] = y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae5311e40964354afaf98f5303c57c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/236345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb8debb53dd49728e577017ba1fcaa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/236345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v_labels = []\n",
    "v_encoder = LabelEncoder()\n",
    "v_encoder_one_hot = OneHotEncoder(sparse=False)\n",
    "v_encoder = v_encoder.fit(df['v_gene'].unique())\n",
    "v_encoder_one_hot = v_encoder_one_hot.fit(v_encoder.transform(df['v_gene'].unique()).reshape(-1,1))\n",
    "for k in tqdm(df.index):\n",
    "    v_label = v_encoder.transform([df.loc[k,\"v_gene\"]])\n",
    "    v_label = v_encoder_one_hot.transform(v_label.reshape(-1,1))\n",
    "    v_labels.append(v_label)\n",
    "df[\"v_gene_one_hot\"] = v_labels\n",
    "\n",
    "j_labels = []\n",
    "j_encoder = LabelEncoder()\n",
    "j_encoder_one_hot = OneHotEncoder(sparse=False)\n",
    "j_encoder = j_encoder.fit(df['j_gene'].unique())\n",
    "j_encoder_one_hot = j_encoder_one_hot.fit(j_encoder.transform(df['j_gene'].unique()).reshape(-1,1))\n",
    "for k in tqdm(df.index):\n",
    "    j_label = j_encoder.transform([df.loc[k,\"j_gene\"]])\n",
    "    j_label = j_encoder_one_hot.transform(j_label.reshape(-1,1))\n",
    "    j_labels.append(j_label)\n",
    "df[\"j_gene_one_hot\"] = j_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 54)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df['j_gene'].unique()))\n",
    "print(len(df['v_gene'].unique()))\n",
    "df[\"v_gene_one_hot\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "            \"comment\": \"This is how models and their training parameters are specified. See tcr_vae.py for reference. Note that the training parameters are quite insufficient for training a real model.\",\n",
    "            \"model\": \"basic\",\n",
    "            \"latent_dim\": 20,\n",
    "            \"dense_nodes\": 75,\n",
    "            \"aa_embedding_dim\": 21,\n",
    "            \"v_gene_embedding_dim\": 54,\n",
    "            \"j_gene_embedding_dim\": 13,\n",
    "            \"beta\": 0.75,\n",
    "            \"max_cdr3_len\": 20,\n",
    "            \"n_aas\": 21,\n",
    "            \"n_v_genes\": 54,\n",
    "            \"n_j_genes\": 13,\n",
    "            \"stopping_monitor\": \"val_loss\",\n",
    "            \"batch_size\": 100,\n",
    "            \"pretrains\": 2,\n",
    "            \"warmup_period\": 3,\n",
    "            \"epochs\": 10,\n",
    "            \"patience\": 20\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " cdr3_input (InputLayer)        [(None, 20, 21)]     0           []                               \n",
      "                                                                                                  \n",
      " cdr3_embedding (EmbedViaMatrix  (None, 20, 21)      441         ['cdr3_input[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " v_gene_input (InputLayer)      [(None, 54)]         0           []                               \n",
      "                                                                                                  \n",
      " j_gene_input (InputLayer)      [(None, 13)]         0           []                               \n",
      "                                                                                                  \n",
      " cdr3_embedding_flat (Reshape)  (None, 420)          0           ['cdr3_embedding[0][0]']         \n",
      "                                                                                                  \n",
      " v_gene_embedding (Dense)       (None, 54)           2970        ['v_gene_input[0][0]']           \n",
      "                                                                                                  \n",
      " j_gene_embedding (Dense)       (None, 13)           182         ['j_gene_input[0][0]']           \n",
      "                                                                                                  \n",
      " merged_embedding (Concatenate)  (None, 487)         0           ['cdr3_embedding_flat[0][0]',    \n",
      "                                                                  'v_gene_embedding[0][0]',       \n",
      "                                                                  'j_gene_embedding[0][0]']       \n",
      "                                                                                                  \n",
      " encoder_dense_1 (Dense)        (None, 75)           36600       ['merged_embedding[0][0]']       \n",
      "                                                                                                  \n",
      " encoder_dense_2 (Dense)        (None, 75)           5700        ['encoder_dense_1[0][0]']        \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 20)           1520        ['encoder_dense_2[0][0]']        \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 20)           1520        ['encoder_dense_2[0][0]']        \n",
      "                                                                                                  \n",
      " z (Lambda)                     (100, 20)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      " decoder_dense_1 (Dense)        multiple             1575        ['z[0][0]']                      \n",
      "                                                                                                  \n",
      " decoder_dense_2 (Dense)        multiple             5700        ['decoder_dense_1[0][0]']        \n",
      "                                                                                                  \n",
      " cdr3_post_dense_flat (Dense)   multiple             31920       ['decoder_dense_2[0][0]']        \n",
      "                                                                                                  \n",
      " cdr3_post_dense (Reshape)      multiple             0           ['cdr3_post_dense_flat[0][0]']   \n",
      "                                                                                                  \n",
      " cdr3_output (Activation)       multiple             0           ['cdr3_post_dense[0][0]']        \n",
      "                                                                                                  \n",
      " v_gene_output (Dense)          multiple             4104        ['decoder_dense_2[0][0]']        \n",
      "                                                                                                  \n",
      " j_gene_output (Dense)          multiple             988         ['decoder_dense_2[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 93,220\n",
      "Trainable params: 93,220\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VAE_vampire.build(params)[\"vae\"]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import vampire_preprocess\n",
    "import vampire_vector_conversion as conversion\n",
    "\n",
    "df.rename(columns={\"CDR3\": \"amino_acid\"}, inplace=True)\n",
    "df = vampire_preprocess.apply_all_filters(df)\n",
    "\n",
    "df = df[['amino_acid', 'v_gene', 'j_gene']]\n",
    "data = conversion.unpadded_tcrbs_to_onehot(df, params['max_cdr3_len'])\n",
    "data = VAE_vampire.prepare_data(data)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation, Dense, Lambda, Input, Reshape\n",
    "from keras import backend as K\n",
    "from keras import losses\n",
    "\n",
    "import vampire_common as common\n",
    "from vampire_custom_keras import BetaWarmup, EmbedViaMatrix\n",
    "\n",
    "\n",
    "def build(params):\n",
    "\n",
    "    beta = K.variable(params['beta'])\n",
    "\n",
    "    def sampling(args):\n",
    "        \"\"\"\n",
    "        This function draws a sample from the multivariate normal defined by\n",
    "        the latent variables.\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=(params['batch_size'], params['latent_dim']), mean=0.0, stddev=1.0)\n",
    "        # Reparameterization trick!\n",
    "        return (z_mean + K.exp(z_log_var / 2) * epsilon)\n",
    "\n",
    "    def vae_cdr3_loss(io_encoder, io_decoder):\n",
    "        \"\"\"\n",
    "        The loss function is the sum of the cross-entropy and KL divergence. KL\n",
    "        gets a weight of beta.\n",
    "        \"\"\"\n",
    "        # Here we multiply by the number of sites, so that we have a\n",
    "        # total loss across the sites rather than a mean loss.\n",
    "        xent_loss = params['max_cdr3_len'] * K.mean(losses.categorical_crossentropy(io_encoder, io_decoder))\n",
    "        kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        kl_loss *= beta\n",
    "        return (xent_loss + kl_loss)\n",
    "\n",
    "    # Input:\n",
    "    cdr3_input_shape = (params['max_cdr3_len'], params['n_aas'])\n",
    "    cdr3_input = Input(shape=cdr3_input_shape, name='cdr3_input')\n",
    "    v_gene_input = Input(shape=(params['n_v_genes'], ), name='v_gene_input')\n",
    "    j_gene_input = Input(shape=(params['n_j_genes'], ), name='j_gene_input')\n",
    "\n",
    "    # Encoding layers:\n",
    "    cdr3_embedding = EmbedViaMatrix(params['aa_embedding_dim'], name='cdr3_embedding')(cdr3_input)\n",
    "    cdr3_embedding_flat = Reshape([params['aa_embedding_dim'] * params['max_cdr3_len']],\n",
    "                                  name='cdr3_embedding_flat')(cdr3_embedding)\n",
    "    v_gene_embedding = Dense(params['v_gene_embedding_dim'], name='v_gene_embedding')(v_gene_input)\n",
    "    j_gene_embedding = Dense(params['j_gene_embedding_dim'], name='j_gene_embedding')(j_gene_input)\n",
    "    merged_embedding = keras.layers.concatenate([cdr3_embedding_flat, v_gene_embedding, j_gene_embedding],\n",
    "                                                name='merged_embedding')\n",
    "    encoder_dense_1 = Dense(params['dense_nodes'], activation='elu', name='encoder_dense_1')(merged_embedding)\n",
    "    encoder_dense_2 = Dense(params['dense_nodes'], activation='elu', name='encoder_dense_2')(encoder_dense_1)\n",
    "\n",
    "    # Latent layers:\n",
    "    z_mean = Dense(params['latent_dim'], name='z_mean')(encoder_dense_2)\n",
    "    z_log_var = Dense(params['latent_dim'], name='z_log_var')(encoder_dense_2)\n",
    "\n",
    "    # Decoding layers:\n",
    "    z_l = Lambda(sampling, output_shape=(params['latent_dim'], ), name='z')\n",
    "    decoder_dense_1_l = Dense(params['dense_nodes'], activation='elu', name='decoder_dense_1')\n",
    "    decoder_dense_2_l = Dense(params['dense_nodes'], activation='elu', name='decoder_dense_2')\n",
    "    cdr3_post_dense_flat_l = Dense(np.array(cdr3_input_shape).prod(), activation='linear', name='cdr3_post_dense_flat')\n",
    "    cdr3_post_dense_reshape_l = Reshape(cdr3_input_shape, name='cdr3_post_dense')\n",
    "    cdr3_output_l = Activation(activation='softmax', name='cdr3_output')\n",
    "    v_gene_output_l = Dense(params['n_v_genes'], activation='softmax', name='v_gene_output')\n",
    "    j_gene_output_l = Dense(params['n_j_genes'], activation='softmax', name='j_gene_output')\n",
    "\n",
    "    post_decoder = decoder_dense_2_l(decoder_dense_1_l(z_l([z_mean, z_log_var])))\n",
    "    cdr3_output = cdr3_output_l(cdr3_post_dense_reshape_l(cdr3_post_dense_flat_l(post_decoder)))\n",
    "    v_gene_output = v_gene_output_l(post_decoder)\n",
    "    j_gene_output = j_gene_output_l(post_decoder)\n",
    "\n",
    "    # Define the decoder components separately so we can have it as its own model.\n",
    "    z_mean_input = Input(shape=(params['latent_dim'], ))\n",
    "    decoder_post_decoder = decoder_dense_2_l(decoder_dense_1_l(z_mean_input))\n",
    "    decoder_cdr3_output = cdr3_output_l(cdr3_post_dense_reshape_l(cdr3_post_dense_flat_l(decoder_post_decoder)))\n",
    "    decoder_v_gene_output = v_gene_output_l(decoder_post_decoder)\n",
    "    decoder_j_gene_output = j_gene_output_l(decoder_post_decoder)\n",
    "\n",
    "    encoder = Model([cdr3_input, v_gene_input, j_gene_input], [z_mean, z_log_var])\n",
    "    decoder = Model(z_mean_input, [decoder_cdr3_output, decoder_v_gene_output, decoder_j_gene_output])\n",
    "    vae = Model([cdr3_input, v_gene_input, j_gene_input], [cdr3_output, v_gene_output, j_gene_output])\n",
    "    vae.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss={\n",
    "            'cdr3_output': vae_cdr3_loss,\n",
    "            'v_gene_output': keras.losses.categorical_crossentropy,\n",
    "            'j_gene_output': keras.losses.categorical_crossentropy,\n",
    "        },\n",
    "        loss_weights={\n",
    "            # Keep the cdr3_output weight to be 1. The weights are relative\n",
    "            # anyhow, and buried inside the vae_cdr3_loss is a beta weight that\n",
    "            # determines how much weight the KL loss has. If we keep this\n",
    "            # weight as 1 then we can interpret beta in a straightforward way.\n",
    "            \"cdr3_output\": 1,\n",
    "            \"j_gene_output\": 0.1305,\n",
    "            \"v_gene_output\": 0.8138\n",
    "        })\n",
    "\n",
    "    callbacks = [BetaWarmup(beta, params['beta'], params['warmup_period'])]\n",
    "\n",
    "    return {'encoder': encoder, 'decoder': decoder, 'vae': vae, 'callbacks': callbacks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build(params)[\"vae\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-c61b55e9120b>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"v_gene_one_hot\"]  = data[\"v_gene_one_hot\"].apply(lambda x: x.reshape(54))\n",
      "<ipython-input-29-c61b55e9120b>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"j_gene_one_hot\"]  = data[\"j_gene_one_hot\"].apply(lambda x: x.reshape(13))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.multiply_4), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=() dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\compile_utils.py\", line 215, in __call__\n        metric_obj.update_state(loss_metric_value, sample_weight=batch_dim)\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\metrics_utils.py\", line 73, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\metrics.py\", line 177, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\metrics.py\", line 451, in update_state  **\n        sample_weight = tf.__internal__.ops.broadcast_weights(\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\keras_tensor.py\", line 255, in __array__\n        raise TypeError(\n\n    TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'tf.cast_7'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-c61b55e9120b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#X_train_v_gene = tf.constant(df[\"v_gene\"].to_numpy())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#X_train_j_gene = tf.constant(df[\"j_gene\"].to_numpy())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\compile_utils.py\", line 215, in __call__\n        metric_obj.update_state(loss_metric_value, sample_weight=batch_dim)\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\metrics_utils.py\", line 73, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\metrics.py\", line 177, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\metrics.py\", line 451, in update_state  **\n        sample_weight = tf.__internal__.ops.broadcast_weights(\n    File \"C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\keras_tensor.py\", line 255, in __array__\n        raise TypeError(\n\n    TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'tf.cast_7'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "data = df[['CDR3_al_one_hot', 'v_gene_one_hot', 'j_gene_one_hot']]\n",
    "data[\"v_gene_one_hot\"]  = data[\"v_gene_one_hot\"].apply(lambda x: x.reshape(54))\n",
    "data[\"j_gene_one_hot\"]  = data[\"j_gene_one_hot\"].apply(lambda x: x.reshape(13))\n",
    "data = [np.stack(col.values) for _, col in data.items()]\n",
    "#X_train = tf.constant(df[\"CDR3\"].to_numpy())\n",
    "#X_train_v_gene = tf.constant(df[\"v_gene\"].to_numpy())\n",
    "#X_train_j_gene = tf.constant(df[\"j_gene\"].to_numpy())\n",
    "model.fit(data, data, epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d954cd638a1e7c86344e891e12f64c2dae4614b72a421e6b381622588a12ad0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
