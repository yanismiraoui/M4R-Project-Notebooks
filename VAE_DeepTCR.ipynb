{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sonnia.processing import Processing\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-45ef339bb706>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'peptide-detail-ci_filtered_aligned_merged.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Amino Acids 1\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Amino Acids\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"CDR3\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"v_gene\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"j_gene\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1196\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1198\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2155\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2157\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2158\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2159\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._concatenate_chunks\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yanis\\anaconda3\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('peptide-detail-ci_filtered_aligned_merged.csv')\n",
    "df[\"Amino Acids 1\"] = df[\"Amino Acids\"].apply(lambda x: x.split(\",\")[0])\n",
    "sub = df[[\"CDR3\", \"v_gene\", \"j_gene\"]]\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py:4300: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "sub.rename(columns={\"CDR3\": \"beta\", \"v_gene\": \"v_beta\", \"j_gene\": \"j_beta\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-d5cc1c6305bf>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub[\"counts\"] = 1\n"
     ]
    }
   ],
   "source": [
    "sub[\"counts\"] = 1\n",
    "sub.to_csv(\"deeptcr_input.tsv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = sub.sample(10000).reset_index(drop=True)\n",
    "small.to_csv(\"deeptcr_input_small.tsv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Embedding Sequences...\n",
      "Data Loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\functions\\Layers.py:105: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv = tf.compat.v1.layers.conv2d(inputs, units[ii], (1, kernel), 1, padding='same',\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\legacy_tf_layers\\convolutional.py:563: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\functions\\Layers.py:107: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  conv_out = tf.compat.v1.layers.flatten(tf.reduce_max(input_tensor=conv, axis=2))\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\legacy_tf_layers\\core.py:523: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\functions\\Layers.py:110: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  conv = tf.compat.v1.layers.dropout(conv, prob)\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\legacy_tf_layers\\core.py:401: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs, training=training)\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\functions\\Layers.py:113: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv = tf.compat.v1.layers.conv2d(conv, units[ii], (1, kernel), (1, kernel), padding='same',\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\functions\\Layers.py:116: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  conv = tf.compat.v1.layers.dropout(conv, prob)\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\functions\\Layers.py:119: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  conv_3_out = tf.compat.v1.layers.flatten(tf.reduce_max(input_tensor=conv_3,axis=2))\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\functions\\Layers.py:122: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  return tf.compat.v1.layers.flatten(conv_3),conv_out,indices\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\DeepTCR.py:1984: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  fc = tf.compat.v1.layers.dense(GO.Features, 256)\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\legacy_tf_layers\\core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\DeepTCR.py:1985: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  fc = tf.compat.v1.layers.dense(fc, latent_dim)\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\DeepTCR.py:1989: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  z_log_var = tf.compat.v1.layers.dense(fc, latent_dim, activation=tf.nn.softplus, name='z_log_var')\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\DeepTCR.py:1995: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  fc_up = tf.compat.v1.layers.dense(z, 128)\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\DeepTCR.py:1996: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  fc_up = tf.compat.v1.layers.dense(fc_up, 256)\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\DeepTCR.py:2014: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "  upsample_beta = tf.compat.v1.layers.conv2d_transpose(upsample_beta, units[-1-_], (1, 3), (1, 2),activation=tf.nn.relu)\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\legacy_tf_layers\\convolutional.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\functions\\Layers.py:250: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "  upsample3_beta = tf.compat.v1.layers.conv2d_transpose(upsample2_beta, GO.embedding_dim_aa, (1, kr), (1, str),\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\DeepTCR.py:2019: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "  upsample3_beta = tf.compat.v1.layers.conv2d_transpose(upsample_beta, GO.embedding_dim_aa, (1, kr),(1, str), activation=tf.nn.relu)\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\functions\\Layers.py:276: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  upsample1 = tf.compat.v1.layers.dense(fc, 128, tf.nn.relu)\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\functions\\Layers.py:277: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  upsample2 = tf.compat.v1.layers.dense(upsample1, 64, tf.nn.relu)\n",
      "C:\\Users\\yanis\\AppData\\Roaming\\Python\\Python38\\site-packages\\DeepTCR\\functions\\Layers.py:278: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  upsample3 = tf.compat.v1.layers.dense(upsample2, embedding_layer.shape[1], tf.nn.relu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, Iteration = 0 Total Loss: 8.42553: Recon Loss: 8.34428: Latent Loss: 0.08125: Sparsity Loss: 0.00000: Recon Accuracy: 0.06130\n",
      "Epoch = 1, Iteration = 0 Total Loss: 7.96055: Recon Loss: 7.87918: Latent Loss: 0.08137: Sparsity Loss: 0.00000: Recon Accuracy: 0.09431\n",
      "Epoch = 2, Iteration = 0 Total Loss: 7.64857: Recon Loss: 7.56286: Latent Loss: 0.08571: Sparsity Loss: 0.00000: Recon Accuracy: 0.11870\n",
      "Epoch = 3, Iteration = 0 Total Loss: 7.39367: Recon Loss: 7.29092: Latent Loss: 0.10275: Sparsity Loss: 0.00000: Recon Accuracy: 0.14995\n",
      "Epoch = 4, Iteration = 0 Total Loss: 7.24945: Recon Loss: 7.10647: Latent Loss: 0.14298: Sparsity Loss: 0.00000: Recon Accuracy: 0.19483\n",
      "Epoch = 5, Iteration = 0 Total Loss: 7.09427: Recon Loss: 6.96375: Latent Loss: 0.13052: Sparsity Loss: 0.00000: Recon Accuracy: 0.22815\n",
      "Epoch = 6, Iteration = 0 Total Loss: 6.96630: Recon Loss: 6.86213: Latent Loss: 0.10417: Sparsity Loss: 0.00000: Recon Accuracy: 0.24466\n",
      "Epoch = 7, Iteration = 0 Total Loss: 6.86032: Recon Loss: 6.77097: Latent Loss: 0.08935: Sparsity Loss: 0.00000: Recon Accuracy: 0.26543\n",
      "Epoch = 8, Iteration = 0 Total Loss: 6.71998: Recon Loss: 6.63622: Latent Loss: 0.08376: Sparsity Loss: 0.00000: Recon Accuracy: 0.28784\n",
      "Epoch = 9, Iteration = 0 Total Loss: 6.56154: Recon Loss: 6.47749: Latent Loss: 0.08405: Sparsity Loss: 0.00000: Recon Accuracy: 0.30387\n",
      "Epoch = 10, Iteration = 0 Total Loss: 6.42056: Recon Loss: 6.33624: Latent Loss: 0.08432: Sparsity Loss: 0.00000: Recon Accuracy: 0.31558\n",
      "Epoch = 11, Iteration = 0 Total Loss: 6.23765: Recon Loss: 6.15913: Latent Loss: 0.07852: Sparsity Loss: 0.00000: Recon Accuracy: 0.32936\n",
      "Epoch = 12, Iteration = 0 Total Loss: 6.04717: Recon Loss: 5.97411: Latent Loss: 0.07306: Sparsity Loss: 0.00000: Recon Accuracy: 0.34523\n",
      "Epoch = 13, Iteration = 0 Total Loss: 5.86038: Recon Loss: 5.78734: Latent Loss: 0.07303: Sparsity Loss: 0.00000: Recon Accuracy: 0.36000\n",
      "Epoch = 14, Iteration = 0 Total Loss: 5.66159: Recon Loss: 5.58391: Latent Loss: 0.07768: Sparsity Loss: 0.00000: Recon Accuracy: 0.36856\n",
      "Epoch = 15, Iteration = 0 Total Loss: 5.49767: Recon Loss: 5.41558: Latent Loss: 0.08209: Sparsity Loss: 0.00000: Recon Accuracy: 0.37276\n",
      "Epoch = 16, Iteration = 0 Total Loss: 5.33315: Recon Loss: 5.25071: Latent Loss: 0.08243: Sparsity Loss: 0.00000: Recon Accuracy: 0.38251\n",
      "Epoch = 17, Iteration = 0 Total Loss: 5.20513: Recon Loss: 5.12056: Latent Loss: 0.08457: Sparsity Loss: 0.00000: Recon Accuracy: 0.39913\n",
      "Epoch = 18, Iteration = 0 Total Loss: 5.07256: Recon Loss: 4.97983: Latent Loss: 0.09273: Sparsity Loss: 0.00000: Recon Accuracy: 0.40646\n",
      "Epoch = 19, Iteration = 0 Total Loss: 4.94315: Recon Loss: 4.84005: Latent Loss: 0.10310: Sparsity Loss: 0.00000: Recon Accuracy: 0.41817\n",
      "Epoch = 20, Iteration = 0 Total Loss: 4.82084: Recon Loss: 4.70979: Latent Loss: 0.11104: Sparsity Loss: 0.00000: Recon Accuracy: 0.43231\n",
      "Epoch = 21, Iteration = 0 Total Loss: 4.66236: Recon Loss: 4.54037: Latent Loss: 0.12199: Sparsity Loss: 0.00000: Recon Accuracy: 0.46353\n",
      "Epoch = 22, Iteration = 0 Total Loss: 4.52610: Recon Loss: 4.38959: Latent Loss: 0.13652: Sparsity Loss: 0.00000: Recon Accuracy: 0.48450\n",
      "Epoch = 23, Iteration = 0 Total Loss: 4.39517: Recon Loss: 4.24821: Latent Loss: 0.14696: Sparsity Loss: 0.00000: Recon Accuracy: 0.49358\n",
      "Epoch = 24, Iteration = 0 Total Loss: 4.24386: Recon Loss: 4.08197: Latent Loss: 0.16189: Sparsity Loss: 0.00000: Recon Accuracy: 0.50494\n",
      "Epoch = 25, Iteration = 0 Total Loss: 4.10395: Recon Loss: 3.93524: Latent Loss: 0.16871: Sparsity Loss: 0.00000: Recon Accuracy: 0.51539\n",
      "Epoch = 26, Iteration = 0 Total Loss: 3.97536: Recon Loss: 3.80004: Latent Loss: 0.17532: Sparsity Loss: 0.00000: Recon Accuracy: 0.52574\n",
      "Epoch = 27, Iteration = 0 Total Loss: 3.85617: Recon Loss: 3.67330: Latent Loss: 0.18286: Sparsity Loss: 0.00000: Recon Accuracy: 0.53641\n",
      "Epoch = 28, Iteration = 0 Total Loss: 3.72841: Recon Loss: 3.54394: Latent Loss: 0.18447: Sparsity Loss: 0.00000: Recon Accuracy: 0.55060\n",
      "Epoch = 29, Iteration = 0 Total Loss: 3.59956: Recon Loss: 3.40681: Latent Loss: 0.19275: Sparsity Loss: 0.00000: Recon Accuracy: 0.56247\n",
      "Epoch = 30, Iteration = 0 Total Loss: 3.47805: Recon Loss: 3.28252: Latent Loss: 0.19553: Sparsity Loss: 0.00000: Recon Accuracy: 0.57840\n",
      "Epoch = 31, Iteration = 0 Total Loss: 3.33999: Recon Loss: 3.14031: Latent Loss: 0.19968: Sparsity Loss: 0.00000: Recon Accuracy: 0.58920\n",
      "Epoch = 32, Iteration = 0 Total Loss: 3.22495: Recon Loss: 3.02157: Latent Loss: 0.20338: Sparsity Loss: 0.00000: Recon Accuracy: 0.59980\n",
      "Epoch = 33, Iteration = 0 Total Loss: 3.11263: Recon Loss: 2.91059: Latent Loss: 0.20204: Sparsity Loss: 0.00000: Recon Accuracy: 0.61373\n",
      "Epoch = 34, Iteration = 0 Total Loss: 3.00566: Recon Loss: 2.80058: Latent Loss: 0.20507: Sparsity Loss: 0.00000: Recon Accuracy: 0.62420\n",
      "Epoch = 35, Iteration = 0 Total Loss: 2.90472: Recon Loss: 2.69900: Latent Loss: 0.20572: Sparsity Loss: 0.00000: Recon Accuracy: 0.63516\n",
      "Epoch = 36, Iteration = 0 Total Loss: 2.81428: Recon Loss: 2.61003: Latent Loss: 0.20425: Sparsity Loss: 0.00000: Recon Accuracy: 0.63947\n",
      "Epoch = 37, Iteration = 0 Total Loss: 2.71457: Recon Loss: 2.50973: Latent Loss: 0.20484: Sparsity Loss: 0.00000: Recon Accuracy: 0.64818\n",
      "Epoch = 38, Iteration = 0 Total Loss: 2.62543: Recon Loss: 2.42008: Latent Loss: 0.20534: Sparsity Loss: 0.00000: Recon Accuracy: 0.65764\n",
      "Epoch = 39, Iteration = 0 Total Loss: 2.54722: Recon Loss: 2.33936: Latent Loss: 0.20786: Sparsity Loss: 0.00000: Recon Accuracy: 0.66765\n",
      "Epoch = 40, Iteration = 0 Total Loss: 2.45444: Recon Loss: 2.24510: Latent Loss: 0.20934: Sparsity Loss: 0.00000: Recon Accuracy: 0.67883\n",
      "Epoch = 41, Iteration = 0 Total Loss: 2.36791: Recon Loss: 2.15692: Latent Loss: 0.21100: Sparsity Loss: 0.00000: Recon Accuracy: 0.68759\n",
      "Epoch = 42, Iteration = 0 Total Loss: 2.27574: Recon Loss: 2.06321: Latent Loss: 0.21253: Sparsity Loss: 0.00000: Recon Accuracy: 0.69768\n",
      "Epoch = 43, Iteration = 0 Total Loss: 2.19599: Recon Loss: 1.98312: Latent Loss: 0.21287: Sparsity Loss: 0.00000: Recon Accuracy: 0.70296\n",
      "Epoch = 44, Iteration = 0 Total Loss: 2.15091: Recon Loss: 1.93750: Latent Loss: 0.21341: Sparsity Loss: 0.00000: Recon Accuracy: 0.70912\n",
      "Epoch = 45, Iteration = 0 Total Loss: 2.04797: Recon Loss: 1.83492: Latent Loss: 0.21305: Sparsity Loss: 0.00000: Recon Accuracy: 0.71540\n",
      "Epoch = 46, Iteration = 0 Total Loss: 1.93862: Recon Loss: 1.72262: Latent Loss: 0.21601: Sparsity Loss: 0.00000: Recon Accuracy: 0.72678\n",
      "Epoch = 47, Iteration = 0 Total Loss: 1.88890: Recon Loss: 1.67172: Latent Loss: 0.21718: Sparsity Loss: 0.00000: Recon Accuracy: 0.73156\n",
      "Epoch = 48, Iteration = 0 Total Loss: 1.80113: Recon Loss: 1.57957: Latent Loss: 0.22156: Sparsity Loss: 0.00000: Recon Accuracy: 0.74196\n",
      "Epoch = 49, Iteration = 0 Total Loss: 1.74128: Recon Loss: 1.51898: Latent Loss: 0.22231: Sparsity Loss: 0.00000: Recon Accuracy: 0.74999\n",
      "Epoch = 50, Iteration = 0 Total Loss: 1.68424: Recon Loss: 1.46009: Latent Loss: 0.22415: Sparsity Loss: 0.00000: Recon Accuracy: 0.75634\n",
      "Epoch = 51, Iteration = 0 Total Loss: 1.61620: Recon Loss: 1.39070: Latent Loss: 0.22551: Sparsity Loss: 0.00000: Recon Accuracy: 0.76152\n",
      "Epoch = 52, Iteration = 0 Total Loss: 1.59614: Recon Loss: 1.37003: Latent Loss: 0.22611: Sparsity Loss: 0.00000: Recon Accuracy: 0.76435\n",
      "Epoch = 53, Iteration = 0 Total Loss: 1.51779: Recon Loss: 1.28815: Latent Loss: 0.22964: Sparsity Loss: 0.00000: Recon Accuracy: 0.77338\n",
      "Epoch = 54, Iteration = 0 Total Loss: 1.48453: Recon Loss: 1.25111: Latent Loss: 0.23343: Sparsity Loss: 0.00000: Recon Accuracy: 0.77457\n",
      "Epoch = 55, Iteration = 0 Total Loss: 1.44364: Recon Loss: 1.21077: Latent Loss: 0.23287: Sparsity Loss: 0.00000: Recon Accuracy: 0.77954\n",
      "Epoch = 56, Iteration = 0 Total Loss: 1.41171: Recon Loss: 1.17765: Latent Loss: 0.23406: Sparsity Loss: 0.00000: Recon Accuracy: 0.78275\n",
      "Epoch = 57, Iteration = 0 Total Loss: 1.37185: Recon Loss: 1.13416: Latent Loss: 0.23770: Sparsity Loss: 0.00000: Recon Accuracy: 0.78569\n",
      "Epoch = 58, Iteration = 0 Total Loss: 1.33522: Recon Loss: 1.09853: Latent Loss: 0.23669: Sparsity Loss: 0.00000: Recon Accuracy: 0.79140\n",
      "Epoch = 59, Iteration = 0 Total Loss: 1.30304: Recon Loss: 1.06669: Latent Loss: 0.23635: Sparsity Loss: 0.00000: Recon Accuracy: 0.79332\n",
      "Epoch = 60, Iteration = 0 Total Loss: 1.26273: Recon Loss: 1.02456: Latent Loss: 0.23816: Sparsity Loss: 0.00000: Recon Accuracy: 0.79747\n",
      "Epoch = 61, Iteration = 0 Total Loss: 1.23912: Recon Loss: 1.00089: Latent Loss: 0.23823: Sparsity Loss: 0.00000: Recon Accuracy: 0.80054\n",
      "Epoch = 62, Iteration = 0 Total Loss: 1.21622: Recon Loss: 0.97938: Latent Loss: 0.23685: Sparsity Loss: 0.00000: Recon Accuracy: 0.80197\n",
      "Epoch = 63, Iteration = 0 Total Loss: 1.18364: Recon Loss: 0.94835: Latent Loss: 0.23530: Sparsity Loss: 0.00000: Recon Accuracy: 0.80439\n",
      "Epoch = 64, Iteration = 0 Total Loss: 1.16730: Recon Loss: 0.93386: Latent Loss: 0.23344: Sparsity Loss: 0.00000: Recon Accuracy: 0.80650\n",
      "Epoch = 65, Iteration = 0 Total Loss: 1.13728: Recon Loss: 0.90533: Latent Loss: 0.23194: Sparsity Loss: 0.00000: Recon Accuracy: 0.80939\n",
      "Epoch = 66, Iteration = 0 Total Loss: 1.11953: Recon Loss: 0.88759: Latent Loss: 0.23194: Sparsity Loss: 0.00000: Recon Accuracy: 0.81000\n",
      "Epoch = 67, Iteration = 0 Total Loss: 1.10169: Recon Loss: 0.87138: Latent Loss: 0.23031: Sparsity Loss: 0.00000: Recon Accuracy: 0.81225\n",
      "Epoch = 68, Iteration = 0 Total Loss: 1.08870: Recon Loss: 0.86140: Latent Loss: 0.22730: Sparsity Loss: 0.00000: Recon Accuracy: 0.81272\n",
      "Epoch = 69, Iteration = 0 Total Loss: 1.06829: Recon Loss: 0.84441: Latent Loss: 0.22388: Sparsity Loss: 0.00000: Recon Accuracy: 0.81353\n",
      "Epoch = 70, Iteration = 0 Total Loss: 1.05364: Recon Loss: 0.83202: Latent Loss: 0.22162: Sparsity Loss: 0.00000: Recon Accuracy: 0.81528\n",
      "Epoch = 71, Iteration = 0 Total Loss: 1.04826: Recon Loss: 0.82844: Latent Loss: 0.21982: Sparsity Loss: 0.00000: Recon Accuracy: 0.81525\n",
      "Epoch = 72, Iteration = 0 Total Loss: 1.03326: Recon Loss: 0.81854: Latent Loss: 0.21472: Sparsity Loss: 0.00000: Recon Accuracy: 0.81582\n",
      "Epoch = 73, Iteration = 0 Total Loss: 1.02078: Recon Loss: 0.80634: Latent Loss: 0.21445: Sparsity Loss: 0.00000: Recon Accuracy: 0.81685\n",
      "Epoch = 74, Iteration = 0 Total Loss: 1.00578: Recon Loss: 0.79457: Latent Loss: 0.21121: Sparsity Loss: 0.00000: Recon Accuracy: 0.81757\n",
      "Epoch = 75, Iteration = 0 Total Loss: 0.98747: Recon Loss: 0.77939: Latent Loss: 0.20808: Sparsity Loss: 0.00000: Recon Accuracy: 0.82017\n",
      "Epoch = 76, Iteration = 0 Total Loss: 0.98645: Recon Loss: 0.78283: Latent Loss: 0.20362: Sparsity Loss: 0.00000: Recon Accuracy: 0.81881\n",
      "Epoch = 77, Iteration = 0 Total Loss: 0.96784: Recon Loss: 0.76655: Latent Loss: 0.20129: Sparsity Loss: 0.00000: Recon Accuracy: 0.82064\n",
      "Epoch = 78, Iteration = 0 Total Loss: 0.95946: Recon Loss: 0.76030: Latent Loss: 0.19916: Sparsity Loss: 0.00000: Recon Accuracy: 0.82110\n",
      "Epoch = 79, Iteration = 0 Total Loss: 0.94784: Recon Loss: 0.75085: Latent Loss: 0.19699: Sparsity Loss: 0.00000: Recon Accuracy: 0.82062\n",
      "Epoch = 80, Iteration = 0 Total Loss: 0.93968: Recon Loss: 0.74453: Latent Loss: 0.19514: Sparsity Loss: 0.00000: Recon Accuracy: 0.82204\n",
      "Epoch = 81, Iteration = 0 Total Loss: 0.93898: Recon Loss: 0.74709: Latent Loss: 0.19189: Sparsity Loss: 0.00000: Recon Accuracy: 0.82139\n",
      "Epoch = 82, Iteration = 0 Total Loss: 0.92569: Recon Loss: 0.73571: Latent Loss: 0.18999: Sparsity Loss: 0.00000: Recon Accuracy: 0.82257\n",
      "Epoch = 83, Iteration = 0 Total Loss: 0.91663: Recon Loss: 0.72821: Latent Loss: 0.18842: Sparsity Loss: 0.00000: Recon Accuracy: 0.82326\n",
      "Epoch = 84, Iteration = 0 Total Loss: 0.91111: Recon Loss: 0.72455: Latent Loss: 0.18656: Sparsity Loss: 0.00000: Recon Accuracy: 0.82381\n",
      "Epoch = 85, Iteration = 0 Total Loss: 0.90424: Recon Loss: 0.71808: Latent Loss: 0.18615: Sparsity Loss: 0.00000: Recon Accuracy: 0.82413\n",
      "Epoch = 86, Iteration = 0 Total Loss: 0.89210: Recon Loss: 0.70905: Latent Loss: 0.18305: Sparsity Loss: 0.00000: Recon Accuracy: 0.82427\n",
      "Epoch = 87, Iteration = 0 Total Loss: 0.89019: Recon Loss: 0.70988: Latent Loss: 0.18032: Sparsity Loss: 0.00000: Recon Accuracy: 0.82422\n",
      "Epoch = 88, Iteration = 0 Total Loss: 0.87854: Recon Loss: 0.69878: Latent Loss: 0.17976: Sparsity Loss: 0.00000: Recon Accuracy: 0.82587\n",
      "Epoch = 89, Iteration = 0 Total Loss: 0.86557: Recon Loss: 0.68749: Latent Loss: 0.17807: Sparsity Loss: 0.00000: Recon Accuracy: 0.82588\n",
      "Epoch = 90, Iteration = 0 Total Loss: 0.86690: Recon Loss: 0.69161: Latent Loss: 0.17529: Sparsity Loss: 0.00000: Recon Accuracy: 0.82562\n",
      "Epoch = 91, Iteration = 0 Total Loss: 0.86535: Recon Loss: 0.68959: Latent Loss: 0.17576: Sparsity Loss: 0.00000: Recon Accuracy: 0.82716\n",
      "Epoch = 92, Iteration = 0 Total Loss: 0.86024: Recon Loss: 0.68649: Latent Loss: 0.17375: Sparsity Loss: 0.00000: Recon Accuracy: 0.82693\n",
      "Epoch = 93, Iteration = 0 Total Loss: 0.85784: Recon Loss: 0.68609: Latent Loss: 0.17175: Sparsity Loss: 0.00000: Recon Accuracy: 0.82640\n",
      "Epoch = 94, Iteration = 0 Total Loss: 0.85104: Recon Loss: 0.67975: Latent Loss: 0.17129: Sparsity Loss: 0.00000: Recon Accuracy: 0.82638\n",
      "Epoch = 95, Iteration = 0 Total Loss: 0.84410: Recon Loss: 0.67433: Latent Loss: 0.16976: Sparsity Loss: 0.00000: Recon Accuracy: 0.82791\n",
      "Epoch = 96, Iteration = 0 Total Loss: 0.83587: Recon Loss: 0.66705: Latent Loss: 0.16882: Sparsity Loss: 0.00000: Recon Accuracy: 0.82896\n",
      "Epoch = 97, Iteration = 0 Total Loss: 0.83558: Recon Loss: 0.66656: Latent Loss: 0.16902: Sparsity Loss: 0.00000: Recon Accuracy: 0.82910\n",
      "Epoch = 98, Iteration = 0 Total Loss: 0.82172: Recon Loss: 0.65503: Latent Loss: 0.16669: Sparsity Loss: 0.00000: Recon Accuracy: 0.83051\n",
      "Epoch = 99, Iteration = 0 Total Loss: 0.83010: Recon Loss: 0.66423: Latent Loss: 0.16588: Sparsity Loss: 0.00000: Recon Accuracy: 0.82862\n",
      "Epoch = 100, Iteration = 0 Total Loss: 0.82316: Recon Loss: 0.65564: Latent Loss: 0.16752: Sparsity Loss: 0.00000: Recon Accuracy: 0.83015\n",
      "Epoch = 101, Iteration = 0 Total Loss: 0.81299: Recon Loss: 0.64564: Latent Loss: 0.16735: Sparsity Loss: 0.00000: Recon Accuracy: 0.83152\n",
      "Epoch = 102, Iteration = 0 Total Loss: 0.81220: Recon Loss: 0.64602: Latent Loss: 0.16618: Sparsity Loss: 0.00000: Recon Accuracy: 0.83223\n",
      "Epoch = 103, Iteration = 0 Total Loss: 0.81648: Recon Loss: 0.65179: Latent Loss: 0.16469: Sparsity Loss: 0.00000: Recon Accuracy: 0.83120\n",
      "Epoch = 104, Iteration = 0 Total Loss: 0.81362: Recon Loss: 0.65002: Latent Loss: 0.16360: Sparsity Loss: 0.00000: Recon Accuracy: 0.83055\n",
      "Epoch = 105, Iteration = 0 Total Loss: 0.81165: Recon Loss: 0.64689: Latent Loss: 0.16476: Sparsity Loss: 0.00000: Recon Accuracy: 0.83152\n",
      "Epoch = 106, Iteration = 0 Total Loss: 0.79727: Recon Loss: 0.63270: Latent Loss: 0.16458: Sparsity Loss: 0.00000: Recon Accuracy: 0.83333\n",
      "Epoch = 107, Iteration = 0 Total Loss: 0.79456: Recon Loss: 0.62992: Latent Loss: 0.16464: Sparsity Loss: 0.00000: Recon Accuracy: 0.83348\n",
      "Epoch = 108, Iteration = 0 Total Loss: 0.79040: Recon Loss: 0.62715: Latent Loss: 0.16325: Sparsity Loss: 0.00000: Recon Accuracy: 0.83346\n",
      "Epoch = 109, Iteration = 0 Total Loss: 0.79208: Recon Loss: 0.63148: Latent Loss: 0.16061: Sparsity Loss: 0.00000: Recon Accuracy: 0.83198\n",
      "Epoch = 110, Iteration = 0 Total Loss: 0.78809: Recon Loss: 0.62761: Latent Loss: 0.16048: Sparsity Loss: 0.00000: Recon Accuracy: 0.83261\n",
      "Epoch = 111, Iteration = 0 Total Loss: 0.78354: Recon Loss: 0.62090: Latent Loss: 0.16264: Sparsity Loss: 0.00000: Recon Accuracy: 0.83416\n",
      "Epoch = 112, Iteration = 0 Total Loss: 0.77601: Recon Loss: 0.61382: Latent Loss: 0.16219: Sparsity Loss: 0.00000: Recon Accuracy: 0.83566\n",
      "Epoch = 113, Iteration = 0 Total Loss: 0.77276: Recon Loss: 0.61239: Latent Loss: 0.16037: Sparsity Loss: 0.00000: Recon Accuracy: 0.83604\n",
      "Epoch = 114, Iteration = 0 Total Loss: 0.77487: Recon Loss: 0.61695: Latent Loss: 0.15793: Sparsity Loss: 0.00000: Recon Accuracy: 0.83500\n",
      "Epoch = 115, Iteration = 0 Total Loss: 0.77052: Recon Loss: 0.61406: Latent Loss: 0.15646: Sparsity Loss: 0.00000: Recon Accuracy: 0.83534\n",
      "Epoch = 116, Iteration = 0 Total Loss: 0.76294: Recon Loss: 0.60682: Latent Loss: 0.15612: Sparsity Loss: 0.00000: Recon Accuracy: 0.83510\n",
      "Epoch = 117, Iteration = 0 Total Loss: 0.76654: Recon Loss: 0.61114: Latent Loss: 0.15540: Sparsity Loss: 0.00000: Recon Accuracy: 0.83548\n",
      "Epoch = 118, Iteration = 0 Total Loss: 0.76438: Recon Loss: 0.60945: Latent Loss: 0.15493: Sparsity Loss: 0.00000: Recon Accuracy: 0.83639\n",
      "Epoch = 119, Iteration = 0 Total Loss: 0.76123: Recon Loss: 0.60627: Latent Loss: 0.15495: Sparsity Loss: 0.00000: Recon Accuracy: 0.83675\n",
      "Epoch = 120, Iteration = 0 Total Loss: 0.75481: Recon Loss: 0.60227: Latent Loss: 0.15254: Sparsity Loss: 0.00000: Recon Accuracy: 0.83765\n",
      "Epoch = 121, Iteration = 0 Total Loss: 0.75677: Recon Loss: 0.60664: Latent Loss: 0.15013: Sparsity Loss: 0.00000: Recon Accuracy: 0.83676\n",
      "Epoch = 122, Iteration = 0 Total Loss: 0.75500: Recon Loss: 0.60522: Latent Loss: 0.14977: Sparsity Loss: 0.00000: Recon Accuracy: 0.83693\n",
      "Epoch = 123, Iteration = 0 Total Loss: 0.75534: Recon Loss: 0.60456: Latent Loss: 0.15078: Sparsity Loss: 0.00000: Recon Accuracy: 0.83648\n",
      "Epoch = 124, Iteration = 0 Total Loss: 0.74533: Recon Loss: 0.59419: Latent Loss: 0.15114: Sparsity Loss: 0.00000: Recon Accuracy: 0.83810\n",
      "Epoch = 125, Iteration = 0 Total Loss: 0.74459: Recon Loss: 0.59427: Latent Loss: 0.15032: Sparsity Loss: 0.00000: Recon Accuracy: 0.83925\n",
      "Epoch = 126, Iteration = 0 Total Loss: 0.75219: Recon Loss: 0.60236: Latent Loss: 0.14984: Sparsity Loss: 0.00000: Recon Accuracy: 0.83757\n",
      "Epoch = 127, Iteration = 0 Total Loss: 0.73761: Recon Loss: 0.58854: Latent Loss: 0.14907: Sparsity Loss: 0.00000: Recon Accuracy: 0.83916\n",
      "Epoch = 128, Iteration = 0 Total Loss: 0.74427: Recon Loss: 0.59604: Latent Loss: 0.14823: Sparsity Loss: 0.00000: Recon Accuracy: 0.83825\n",
      "Epoch = 129, Iteration = 0 Total Loss: 0.74289: Recon Loss: 0.59537: Latent Loss: 0.14751: Sparsity Loss: 0.00000: Recon Accuracy: 0.83839\n",
      "Epoch = 130, Iteration = 0 Total Loss: 0.73863: Recon Loss: 0.59138: Latent Loss: 0.14725: Sparsity Loss: 0.00000: Recon Accuracy: 0.84000\n",
      "Epoch = 131, Iteration = 0 Total Loss: 0.73543: Recon Loss: 0.58649: Latent Loss: 0.14894: Sparsity Loss: 0.00000: Recon Accuracy: 0.84093\n",
      "Epoch = 132, Iteration = 0 Total Loss: 0.73183: Recon Loss: 0.58497: Latent Loss: 0.14685: Sparsity Loss: 0.00000: Recon Accuracy: 0.84046\n",
      "Epoch = 133, Iteration = 0 Total Loss: 0.73370: Recon Loss: 0.58841: Latent Loss: 0.14529: Sparsity Loss: 0.00000: Recon Accuracy: 0.83978\n",
      "Epoch = 134, Iteration = 0 Total Loss: 0.73134: Recon Loss: 0.58571: Latent Loss: 0.14563: Sparsity Loss: 0.00000: Recon Accuracy: 0.84187\n",
      "Epoch = 135, Iteration = 0 Total Loss: 0.73544: Recon Loss: 0.58876: Latent Loss: 0.14667: Sparsity Loss: 0.00000: Recon Accuracy: 0.84137\n",
      "Epoch = 136, Iteration = 0 Total Loss: 0.72825: Recon Loss: 0.58391: Latent Loss: 0.14435: Sparsity Loss: 0.00000: Recon Accuracy: 0.84155\n",
      "Epoch = 137, Iteration = 0 Total Loss: 0.72335: Recon Loss: 0.57914: Latent Loss: 0.14422: Sparsity Loss: 0.00000: Recon Accuracy: 0.84218\n",
      "Epoch = 138, Iteration = 0 Total Loss: 0.72181: Recon Loss: 0.57580: Latent Loss: 0.14602: Sparsity Loss: 0.00000: Recon Accuracy: 0.84275\n",
      "Epoch = 139, Iteration = 0 Total Loss: 0.72678: Recon Loss: 0.58122: Latent Loss: 0.14556: Sparsity Loss: 0.00000: Recon Accuracy: 0.84228\n",
      "Epoch = 140, Iteration = 0 Total Loss: 0.71612: Recon Loss: 0.57289: Latent Loss: 0.14323: Sparsity Loss: 0.00000: Recon Accuracy: 0.84416\n",
      "Epoch = 141, Iteration = 0 Total Loss: 0.72695: Recon Loss: 0.58457: Latent Loss: 0.14238: Sparsity Loss: 0.00000: Recon Accuracy: 0.84303\n",
      "Epoch = 142, Iteration = 0 Total Loss: 0.72103: Recon Loss: 0.57778: Latent Loss: 0.14324: Sparsity Loss: 0.00000: Recon Accuracy: 0.84377\n",
      "Epoch = 143, Iteration = 0 Total Loss: 0.71944: Recon Loss: 0.57434: Latent Loss: 0.14510: Sparsity Loss: 0.00000: Recon Accuracy: 0.84350\n",
      "Epoch = 144, Iteration = 0 Total Loss: 0.71452: Recon Loss: 0.57101: Latent Loss: 0.14352: Sparsity Loss: 0.00000: Recon Accuracy: 0.84588\n",
      "Epoch = 145, Iteration = 0 Total Loss: 0.71581: Recon Loss: 0.57345: Latent Loss: 0.14236: Sparsity Loss: 0.00000: Recon Accuracy: 0.84479\n",
      "Epoch = 146, Iteration = 0 Total Loss: 0.71126: Recon Loss: 0.56847: Latent Loss: 0.14279: Sparsity Loss: 0.00000: Recon Accuracy: 0.84534\n",
      "Epoch = 147, Iteration = 0 Total Loss: 0.71255: Recon Loss: 0.56859: Latent Loss: 0.14395: Sparsity Loss: 0.00000: Recon Accuracy: 0.84643\n",
      "Epoch = 148, Iteration = 0 Total Loss: 0.70829: Recon Loss: 0.56641: Latent Loss: 0.14189: Sparsity Loss: 0.00000: Recon Accuracy: 0.84705\n",
      "Epoch = 149, Iteration = 0 Total Loss: 0.70291: Recon Loss: 0.56225: Latent Loss: 0.14066: Sparsity Loss: 0.00000: Recon Accuracy: 0.84801\n",
      "Epoch = 150, Iteration = 0 Total Loss: 0.70581: Recon Loss: 0.56396: Latent Loss: 0.14185: Sparsity Loss: 0.00000: Recon Accuracy: 0.84755\n",
      "Epoch = 151, Iteration = 0 Total Loss: 0.69913: Recon Loss: 0.55665: Latent Loss: 0.14249: Sparsity Loss: 0.00000: Recon Accuracy: 0.84840\n",
      "Epoch = 152, Iteration = 0 Total Loss: 0.69837: Recon Loss: 0.55734: Latent Loss: 0.14103: Sparsity Loss: 0.00000: Recon Accuracy: 0.84942\n",
      "Epoch = 153, Iteration = 0 Total Loss: 0.69226: Recon Loss: 0.55178: Latent Loss: 0.14048: Sparsity Loss: 0.00000: Recon Accuracy: 0.84964\n",
      "Epoch = 154, Iteration = 0 Total Loss: 0.70081: Recon Loss: 0.56059: Latent Loss: 0.14021: Sparsity Loss: 0.00000: Recon Accuracy: 0.84939\n",
      "Epoch = 155, Iteration = 0 Total Loss: 0.69505: Recon Loss: 0.55515: Latent Loss: 0.13991: Sparsity Loss: 0.00000: Recon Accuracy: 0.85008\n",
      "Epoch = 156, Iteration = 0 Total Loss: 0.68878: Recon Loss: 0.54839: Latent Loss: 0.14039: Sparsity Loss: 0.00000: Recon Accuracy: 0.85131\n",
      "Epoch = 157, Iteration = 0 Total Loss: 0.68638: Recon Loss: 0.54584: Latent Loss: 0.14054: Sparsity Loss: 0.00000: Recon Accuracy: 0.85138\n",
      "Epoch = 158, Iteration = 0 Total Loss: 0.69347: Recon Loss: 0.55382: Latent Loss: 0.13965: Sparsity Loss: 0.00000: Recon Accuracy: 0.85112\n",
      "Epoch = 159, Iteration = 0 Total Loss: 0.68383: Recon Loss: 0.54414: Latent Loss: 0.13969: Sparsity Loss: 0.00000: Recon Accuracy: 0.85273\n",
      "Epoch = 160, Iteration = 0 Total Loss: 0.68594: Recon Loss: 0.54664: Latent Loss: 0.13929: Sparsity Loss: 0.00000: Recon Accuracy: 0.85133\n",
      "Epoch = 161, Iteration = 0 Total Loss: 0.69017: Recon Loss: 0.55135: Latent Loss: 0.13882: Sparsity Loss: 0.00000: Recon Accuracy: 0.85249\n",
      "Epoch = 162, Iteration = 0 Total Loss: 0.68928: Recon Loss: 0.55164: Latent Loss: 0.13764: Sparsity Loss: 0.00000: Recon Accuracy: 0.85247\n",
      "Epoch = 163, Iteration = 0 Total Loss: 0.67991: Recon Loss: 0.54122: Latent Loss: 0.13869: Sparsity Loss: 0.00000: Recon Accuracy: 0.85342\n",
      "Epoch = 164, Iteration = 0 Total Loss: 0.68337: Recon Loss: 0.54397: Latent Loss: 0.13940: Sparsity Loss: 0.00000: Recon Accuracy: 0.85418\n",
      "Epoch = 165, Iteration = 0 Total Loss: 0.67981: Recon Loss: 0.54170: Latent Loss: 0.13811: Sparsity Loss: 0.00000: Recon Accuracy: 0.85441\n",
      "Epoch = 166, Iteration = 0 Total Loss: 0.67582: Recon Loss: 0.53772: Latent Loss: 0.13810: Sparsity Loss: 0.00000: Recon Accuracy: 0.85515\n",
      "Epoch = 167, Iteration = 0 Total Loss: 0.67415: Recon Loss: 0.53550: Latent Loss: 0.13866: Sparsity Loss: 0.00000: Recon Accuracy: 0.85538\n",
      "Epoch = 168, Iteration = 0 Total Loss: 0.67499: Recon Loss: 0.53712: Latent Loss: 0.13787: Sparsity Loss: 0.00000: Recon Accuracy: 0.85557\n",
      "Epoch = 169, Iteration = 0 Total Loss: 0.66913: Recon Loss: 0.53201: Latent Loss: 0.13712: Sparsity Loss: 0.00000: Recon Accuracy: 0.85648\n",
      "Epoch = 170, Iteration = 0 Total Loss: 0.66915: Recon Loss: 0.53212: Latent Loss: 0.13703: Sparsity Loss: 0.00000: Recon Accuracy: 0.85628\n",
      "Epoch = 171, Iteration = 0 Total Loss: 0.66640: Recon Loss: 0.52878: Latent Loss: 0.13762: Sparsity Loss: 0.00000: Recon Accuracy: 0.85699\n",
      "Epoch = 172, Iteration = 0 Total Loss: 0.67245: Recon Loss: 0.53395: Latent Loss: 0.13850: Sparsity Loss: 0.00000: Recon Accuracy: 0.85717\n",
      "Epoch = 173, Iteration = 0 Total Loss: 0.66569: Recon Loss: 0.52884: Latent Loss: 0.13685: Sparsity Loss: 0.00000: Recon Accuracy: 0.85779\n",
      "Epoch = 174, Iteration = 0 Total Loss: 0.66521: Recon Loss: 0.52963: Latent Loss: 0.13558: Sparsity Loss: 0.00000: Recon Accuracy: 0.85795\n",
      "Epoch = 175, Iteration = 0 Total Loss: 0.66629: Recon Loss: 0.52997: Latent Loss: 0.13632: Sparsity Loss: 0.00000: Recon Accuracy: 0.85880\n",
      "Epoch = 176, Iteration = 0 Total Loss: 0.66112: Recon Loss: 0.52363: Latent Loss: 0.13749: Sparsity Loss: 0.00000: Recon Accuracy: 0.85949\n",
      "Epoch = 177, Iteration = 0 Total Loss: 0.65703: Recon Loss: 0.52125: Latent Loss: 0.13578: Sparsity Loss: 0.00000: Recon Accuracy: 0.86039\n",
      "Epoch = 178, Iteration = 0 Total Loss: 0.65766: Recon Loss: 0.52243: Latent Loss: 0.13523: Sparsity Loss: 0.00000: Recon Accuracy: 0.86028\n",
      "Epoch = 179, Iteration = 0 Total Loss: 0.65812: Recon Loss: 0.52107: Latent Loss: 0.13706: Sparsity Loss: 0.00000: Recon Accuracy: 0.86098\n",
      "Epoch = 180, Iteration = 0 Total Loss: 0.66576: Recon Loss: 0.52898: Latent Loss: 0.13678: Sparsity Loss: 0.00000: Recon Accuracy: 0.85988\n",
      "Epoch = 181, Iteration = 0 Total Loss: 0.65299: Recon Loss: 0.51732: Latent Loss: 0.13567: Sparsity Loss: 0.00000: Recon Accuracy: 0.86071\n",
      "Epoch = 182, Iteration = 0 Total Loss: 0.65303: Recon Loss: 0.51676: Latent Loss: 0.13628: Sparsity Loss: 0.00000: Recon Accuracy: 0.86099\n",
      "Epoch = 183, Iteration = 0 Total Loss: 0.64444: Recon Loss: 0.50712: Latent Loss: 0.13733: Sparsity Loss: 0.00000: Recon Accuracy: 0.86275\n",
      "Epoch = 184, Iteration = 0 Total Loss: 0.64882: Recon Loss: 0.51066: Latent Loss: 0.13816: Sparsity Loss: 0.00000: Recon Accuracy: 0.86311\n",
      "Epoch = 185, Iteration = 0 Total Loss: 0.65012: Recon Loss: 0.51247: Latent Loss: 0.13765: Sparsity Loss: 0.00000: Recon Accuracy: 0.86298\n",
      "Epoch = 186, Iteration = 0 Total Loss: 0.65177: Recon Loss: 0.51511: Latent Loss: 0.13666: Sparsity Loss: 0.00000: Recon Accuracy: 0.86215\n",
      "Epoch = 187, Iteration = 0 Total Loss: 0.65503: Recon Loss: 0.51766: Latent Loss: 0.13736: Sparsity Loss: 0.00000: Recon Accuracy: 0.86338\n",
      "Epoch = 188, Iteration = 0 Total Loss: 0.64012: Recon Loss: 0.50318: Latent Loss: 0.13693: Sparsity Loss: 0.00000: Recon Accuracy: 0.86564\n",
      "Epoch = 189, Iteration = 0 Total Loss: 0.64828: Recon Loss: 0.51098: Latent Loss: 0.13730: Sparsity Loss: 0.00000: Recon Accuracy: 0.86459\n",
      "Epoch = 190, Iteration = 0 Total Loss: 0.63757: Recon Loss: 0.49946: Latent Loss: 0.13811: Sparsity Loss: 0.00000: Recon Accuracy: 0.86552\n",
      "Epoch = 191, Iteration = 0 Total Loss: 0.64068: Recon Loss: 0.50289: Latent Loss: 0.13778: Sparsity Loss: 0.00000: Recon Accuracy: 0.86587\n",
      "Epoch = 192, Iteration = 0 Total Loss: 0.64463: Recon Loss: 0.50760: Latent Loss: 0.13703: Sparsity Loss: 0.00000: Recon Accuracy: 0.86512\n",
      "Epoch = 193, Iteration = 0 Total Loss: 0.63804: Recon Loss: 0.49996: Latent Loss: 0.13808: Sparsity Loss: 0.00000: Recon Accuracy: 0.86748\n",
      "Epoch = 194, Iteration = 0 Total Loss: 0.63719: Recon Loss: 0.49810: Latent Loss: 0.13909: Sparsity Loss: 0.00000: Recon Accuracy: 0.86774\n",
      "Epoch = 195, Iteration = 0 Total Loss: 0.63148: Recon Loss: 0.49308: Latent Loss: 0.13841: Sparsity Loss: 0.00000: Recon Accuracy: 0.86822\n",
      "Epoch = 196, Iteration = 0 Total Loss: 0.63504: Recon Loss: 0.49774: Latent Loss: 0.13730: Sparsity Loss: 0.00000: Recon Accuracy: 0.86852\n",
      "Epoch = 197, Iteration = 0 Total Loss: 0.63455: Recon Loss: 0.49740: Latent Loss: 0.13714: Sparsity Loss: 0.00000: Recon Accuracy: 0.86900\n",
      "Epoch = 198, Iteration = 0 Total Loss: 0.63407: Recon Loss: 0.49556: Latent Loss: 0.13851: Sparsity Loss: 0.00000: Recon Accuracy: 0.86905\n",
      "Epoch = 199, Iteration = 0 Total Loss: 0.63385: Recon Loss: 0.49473: Latent Loss: 0.13911: Sparsity Loss: 0.00000: Recon Accuracy: 0.86882\n",
      "Epoch = 200, Iteration = 0 Total Loss: 0.62906: Recon Loss: 0.49151: Latent Loss: 0.13755: Sparsity Loss: 0.00000: Recon Accuracy: 0.86999\n",
      "Epoch = 201, Iteration = 0 Total Loss: 0.63401: Recon Loss: 0.49693: Latent Loss: 0.13708: Sparsity Loss: 0.00000: Recon Accuracy: 0.86935\n",
      "Epoch = 202, Iteration = 0 Total Loss: 0.62550: Recon Loss: 0.48701: Latent Loss: 0.13849: Sparsity Loss: 0.00000: Recon Accuracy: 0.87111\n",
      "Epoch = 203, Iteration = 0 Total Loss: 0.62800: Recon Loss: 0.48833: Latent Loss: 0.13967: Sparsity Loss: 0.00000: Recon Accuracy: 0.87070\n",
      "Epoch = 204, Iteration = 0 Total Loss: 0.62698: Recon Loss: 0.48849: Latent Loss: 0.13849: Sparsity Loss: 0.00000: Recon Accuracy: 0.87110\n",
      "Epoch = 205, Iteration = 0 Total Loss: 0.62266: Recon Loss: 0.48468: Latent Loss: 0.13798: Sparsity Loss: 0.00000: Recon Accuracy: 0.87176\n",
      "Epoch = 206, Iteration = 0 Total Loss: 0.62657: Recon Loss: 0.48680: Latent Loss: 0.13977: Sparsity Loss: 0.00000: Recon Accuracy: 0.87224\n",
      "Epoch = 207, Iteration = 0 Total Loss: 0.62063: Recon Loss: 0.48022: Latent Loss: 0.14041: Sparsity Loss: 0.00000: Recon Accuracy: 0.87338\n",
      "Epoch = 208, Iteration = 0 Total Loss: 0.61823: Recon Loss: 0.47900: Latent Loss: 0.13923: Sparsity Loss: 0.00000: Recon Accuracy: 0.87391\n",
      "Epoch = 209, Iteration = 0 Total Loss: 0.62232: Recon Loss: 0.48395: Latent Loss: 0.13838: Sparsity Loss: 0.00000: Recon Accuracy: 0.87211\n",
      "Epoch = 210, Iteration = 0 Total Loss: 0.61569: Recon Loss: 0.47629: Latent Loss: 0.13941: Sparsity Loss: 0.00000: Recon Accuracy: 0.87405\n",
      "Epoch = 211, Iteration = 0 Total Loss: 0.61387: Recon Loss: 0.47332: Latent Loss: 0.14055: Sparsity Loss: 0.00000: Recon Accuracy: 0.87460\n",
      "Epoch = 212, Iteration = 0 Total Loss: 0.60885: Recon Loss: 0.46899: Latent Loss: 0.13986: Sparsity Loss: 0.00000: Recon Accuracy: 0.87582\n",
      "Epoch = 213, Iteration = 0 Total Loss: 0.61331: Recon Loss: 0.47452: Latent Loss: 0.13879: Sparsity Loss: 0.00000: Recon Accuracy: 0.87577\n",
      "Epoch = 214, Iteration = 0 Total Loss: 0.60872: Recon Loss: 0.46999: Latent Loss: 0.13873: Sparsity Loss: 0.00000: Recon Accuracy: 0.87642\n",
      "Epoch = 215, Iteration = 0 Total Loss: 0.61089: Recon Loss: 0.47139: Latent Loss: 0.13950: Sparsity Loss: 0.00000: Recon Accuracy: 0.87606\n",
      "Epoch = 216, Iteration = 0 Total Loss: 0.61147: Recon Loss: 0.47259: Latent Loss: 0.13888: Sparsity Loss: 0.00000: Recon Accuracy: 0.87689\n",
      "Epoch = 217, Iteration = 0 Total Loss: 0.61133: Recon Loss: 0.47366: Latent Loss: 0.13767: Sparsity Loss: 0.00000: Recon Accuracy: 0.87635\n",
      "Epoch = 218, Iteration = 0 Total Loss: 0.60758: Recon Loss: 0.47089: Latent Loss: 0.13668: Sparsity Loss: 0.00000: Recon Accuracy: 0.87708\n",
      "Epoch = 219, Iteration = 0 Total Loss: 0.60782: Recon Loss: 0.47016: Latent Loss: 0.13766: Sparsity Loss: 0.00000: Recon Accuracy: 0.87677\n",
      "Epoch = 220, Iteration = 0 Total Loss: 0.60363: Recon Loss: 0.46536: Latent Loss: 0.13827: Sparsity Loss: 0.00000: Recon Accuracy: 0.87736\n",
      "Epoch = 221, Iteration = 0 Total Loss: 0.60044: Recon Loss: 0.46294: Latent Loss: 0.13750: Sparsity Loss: 0.00000: Recon Accuracy: 0.87839\n",
      "Epoch = 222, Iteration = 0 Total Loss: 0.60205: Recon Loss: 0.46540: Latent Loss: 0.13665: Sparsity Loss: 0.00000: Recon Accuracy: 0.87768\n",
      "Epoch = 223, Iteration = 0 Total Loss: 0.59606: Recon Loss: 0.45978: Latent Loss: 0.13628: Sparsity Loss: 0.00000: Recon Accuracy: 0.87903\n",
      "Epoch = 224, Iteration = 0 Total Loss: 0.59544: Recon Loss: 0.45875: Latent Loss: 0.13669: Sparsity Loss: 0.00000: Recon Accuracy: 0.87930\n",
      "Epoch = 225, Iteration = 0 Total Loss: 0.59287: Recon Loss: 0.45585: Latent Loss: 0.13702: Sparsity Loss: 0.00000: Recon Accuracy: 0.87918\n",
      "Epoch = 226, Iteration = 0 Total Loss: 0.59973: Recon Loss: 0.46355: Latent Loss: 0.13619: Sparsity Loss: 0.00000: Recon Accuracy: 0.87934\n",
      "Epoch = 227, Iteration = 0 Total Loss: 0.59117: Recon Loss: 0.45623: Latent Loss: 0.13495: Sparsity Loss: 0.00000: Recon Accuracy: 0.88068\n",
      "Epoch = 228, Iteration = 0 Total Loss: 0.59816: Recon Loss: 0.46367: Latent Loss: 0.13449: Sparsity Loss: 0.00000: Recon Accuracy: 0.87975\n",
      "Epoch = 229, Iteration = 0 Total Loss: 0.58771: Recon Loss: 0.45235: Latent Loss: 0.13535: Sparsity Loss: 0.00000: Recon Accuracy: 0.88059\n",
      "Epoch = 230, Iteration = 0 Total Loss: 0.59918: Recon Loss: 0.46397: Latent Loss: 0.13521: Sparsity Loss: 0.00000: Recon Accuracy: 0.88006\n",
      "Epoch = 231, Iteration = 0 Total Loss: 0.59249: Recon Loss: 0.45849: Latent Loss: 0.13400: Sparsity Loss: 0.00000: Recon Accuracy: 0.88058\n",
      "Epoch = 232, Iteration = 0 Total Loss: 0.59461: Recon Loss: 0.46073: Latent Loss: 0.13389: Sparsity Loss: 0.00000: Recon Accuracy: 0.88027\n",
      "Epoch = 233, Iteration = 0 Total Loss: 0.58732: Recon Loss: 0.45235: Latent Loss: 0.13497: Sparsity Loss: 0.00000: Recon Accuracy: 0.88166\n",
      "Epoch = 234, Iteration = 0 Total Loss: 0.59038: Recon Loss: 0.45451: Latent Loss: 0.13587: Sparsity Loss: 0.00000: Recon Accuracy: 0.88110\n",
      "Epoch = 235, Iteration = 0 Total Loss: 0.58707: Recon Loss: 0.45254: Latent Loss: 0.13454: Sparsity Loss: 0.00000: Recon Accuracy: 0.88107\n",
      "Epoch = 236, Iteration = 0 Total Loss: 0.59140: Recon Loss: 0.45790: Latent Loss: 0.13350: Sparsity Loss: 0.00000: Recon Accuracy: 0.88073\n",
      "Epoch = 237, Iteration = 0 Total Loss: 0.58938: Recon Loss: 0.45523: Latent Loss: 0.13414: Sparsity Loss: 0.00000: Recon Accuracy: 0.88123\n",
      "Epoch = 238, Iteration = 0 Total Loss: 0.58815: Recon Loss: 0.45336: Latent Loss: 0.13479: Sparsity Loss: 0.00000: Recon Accuracy: 0.88168\n",
      "Epoch = 239, Iteration = 0 Total Loss: 0.58377: Recon Loss: 0.44968: Latent Loss: 0.13408: Sparsity Loss: 0.00000: Recon Accuracy: 0.88255\n",
      "Epoch = 240, Iteration = 0 Total Loss: 0.58573: Recon Loss: 0.45229: Latent Loss: 0.13344: Sparsity Loss: 0.00000: Recon Accuracy: 0.88163\n",
      "Epoch = 241, Iteration = 0 Total Loss: 0.58488: Recon Loss: 0.45040: Latent Loss: 0.13448: Sparsity Loss: 0.00000: Recon Accuracy: 0.88315\n",
      "Epoch = 242, Iteration = 0 Total Loss: 0.58758: Recon Loss: 0.45170: Latent Loss: 0.13588: Sparsity Loss: 0.00000: Recon Accuracy: 0.88299\n",
      "Epoch = 243, Iteration = 0 Total Loss: 0.57695: Recon Loss: 0.44182: Latent Loss: 0.13513: Sparsity Loss: 0.00000: Recon Accuracy: 0.88469\n",
      "Epoch = 244, Iteration = 0 Total Loss: 0.58614: Recon Loss: 0.45243: Latent Loss: 0.13371: Sparsity Loss: 0.00000: Recon Accuracy: 0.88333\n",
      "Epoch = 245, Iteration = 0 Total Loss: 0.57712: Recon Loss: 0.44261: Latent Loss: 0.13451: Sparsity Loss: 0.00000: Recon Accuracy: 0.88435\n",
      "Epoch = 246, Iteration = 0 Total Loss: 0.58041: Recon Loss: 0.44541: Latent Loss: 0.13500: Sparsity Loss: 0.00000: Recon Accuracy: 0.88375\n",
      "Epoch = 247, Iteration = 0 Total Loss: 0.58331: Recon Loss: 0.44804: Latent Loss: 0.13527: Sparsity Loss: 0.00000: Recon Accuracy: 0.88372\n",
      "Epoch = 248, Iteration = 0 Total Loss: 0.57600: Recon Loss: 0.44200: Latent Loss: 0.13400: Sparsity Loss: 0.00000: Recon Accuracy: 0.88492\n",
      "Epoch = 249, Iteration = 0 Total Loss: 0.57690: Recon Loss: 0.44395: Latent Loss: 0.13295: Sparsity Loss: 0.00000: Recon Accuracy: 0.88427\n",
      "Epoch = 250, Iteration = 0 Total Loss: 0.57310: Recon Loss: 0.43997: Latent Loss: 0.13314: Sparsity Loss: 0.00000: Recon Accuracy: 0.88504\n",
      "Epoch = 251, Iteration = 0 Total Loss: 0.57353: Recon Loss: 0.43981: Latent Loss: 0.13372: Sparsity Loss: 0.00000: Recon Accuracy: 0.88455\n",
      "Epoch = 252, Iteration = 0 Total Loss: 0.57123: Recon Loss: 0.43817: Latent Loss: 0.13306: Sparsity Loss: 0.00000: Recon Accuracy: 0.88588\n",
      "Epoch = 253, Iteration = 0 Total Loss: 0.57009: Recon Loss: 0.43763: Latent Loss: 0.13246: Sparsity Loss: 0.00000: Recon Accuracy: 0.88597\n",
      "Epoch = 254, Iteration = 0 Total Loss: 0.57521: Recon Loss: 0.44304: Latent Loss: 0.13217: Sparsity Loss: 0.00000: Recon Accuracy: 0.88528\n",
      "Epoch = 255, Iteration = 0 Total Loss: 0.57676: Recon Loss: 0.44391: Latent Loss: 0.13285: Sparsity Loss: 0.00000: Recon Accuracy: 0.88602\n",
      "Epoch = 256, Iteration = 0 Total Loss: 0.58153: Recon Loss: 0.44762: Latent Loss: 0.13391: Sparsity Loss: 0.00000: Recon Accuracy: 0.88423\n",
      "Epoch = 257, Iteration = 0 Total Loss: 0.57373: Recon Loss: 0.44092: Latent Loss: 0.13281: Sparsity Loss: 0.00000: Recon Accuracy: 0.88587\n",
      "Epoch = 258, Iteration = 0 Total Loss: 0.58242: Recon Loss: 0.44967: Latent Loss: 0.13275: Sparsity Loss: 0.00000: Recon Accuracy: 0.88524\n",
      "Epoch = 259, Iteration = 0 Total Loss: 0.57210: Recon Loss: 0.43821: Latent Loss: 0.13390: Sparsity Loss: 0.00000: Recon Accuracy: 0.88571\n",
      "Epoch = 260, Iteration = 0 Total Loss: 0.57643: Recon Loss: 0.44189: Latent Loss: 0.13454: Sparsity Loss: 0.00000: Recon Accuracy: 0.88630\n",
      "Epoch = 261, Iteration = 0 Total Loss: 0.56677: Recon Loss: 0.43231: Latent Loss: 0.13446: Sparsity Loss: 0.00000: Recon Accuracy: 0.88743\n",
      "Epoch = 262, Iteration = 0 Total Loss: 0.57090: Recon Loss: 0.43653: Latent Loss: 0.13437: Sparsity Loss: 0.00000: Recon Accuracy: 0.88650\n",
      "Epoch = 263, Iteration = 0 Total Loss: 0.56324: Recon Loss: 0.42880: Latent Loss: 0.13444: Sparsity Loss: 0.00000: Recon Accuracy: 0.88719\n",
      "Epoch = 264, Iteration = 0 Total Loss: 0.57245: Recon Loss: 0.43828: Latent Loss: 0.13418: Sparsity Loss: 0.00000: Recon Accuracy: 0.88668\n",
      "Epoch = 265, Iteration = 0 Total Loss: 0.56510: Recon Loss: 0.43108: Latent Loss: 0.13402: Sparsity Loss: 0.00000: Recon Accuracy: 0.88753\n",
      "Epoch = 266, Iteration = 0 Total Loss: 0.56496: Recon Loss: 0.43066: Latent Loss: 0.13429: Sparsity Loss: 0.00000: Recon Accuracy: 0.88780\n",
      "Epoch = 267, Iteration = 0 Total Loss: 0.56736: Recon Loss: 0.43284: Latent Loss: 0.13452: Sparsity Loss: 0.00000: Recon Accuracy: 0.88786\n",
      "Epoch = 268, Iteration = 0 Total Loss: 0.56513: Recon Loss: 0.43123: Latent Loss: 0.13390: Sparsity Loss: 0.00000: Recon Accuracy: 0.88794\n",
      "Epoch = 269, Iteration = 0 Total Loss: 0.56712: Recon Loss: 0.43364: Latent Loss: 0.13348: Sparsity Loss: 0.00000: Recon Accuracy: 0.88717\n",
      "Epoch = 270, Iteration = 0 Total Loss: 0.56699: Recon Loss: 0.43382: Latent Loss: 0.13316: Sparsity Loss: 0.00000: Recon Accuracy: 0.88740\n",
      "Epoch = 271, Iteration = 0 Total Loss: 0.56605: Recon Loss: 0.43217: Latent Loss: 0.13388: Sparsity Loss: 0.00000: Recon Accuracy: 0.88763\n",
      "Epoch = 272, Iteration = 0 Total Loss: 0.56319: Recon Loss: 0.42872: Latent Loss: 0.13447: Sparsity Loss: 0.00000: Recon Accuracy: 0.88843\n",
      "Epoch = 273, Iteration = 0 Total Loss: 0.56701: Recon Loss: 0.43249: Latent Loss: 0.13452: Sparsity Loss: 0.00000: Recon Accuracy: 0.88799\n",
      "Epoch = 274, Iteration = 0 Total Loss: 0.56535: Recon Loss: 0.43167: Latent Loss: 0.13367: Sparsity Loss: 0.00000: Recon Accuracy: 0.88809\n",
      "Epoch = 275, Iteration = 0 Total Loss: 0.56685: Recon Loss: 0.43373: Latent Loss: 0.13313: Sparsity Loss: 0.00000: Recon Accuracy: 0.88814\n",
      "Epoch = 276, Iteration = 0 Total Loss: 0.55570: Recon Loss: 0.42199: Latent Loss: 0.13371: Sparsity Loss: 0.00000: Recon Accuracy: 0.88980\n",
      "Epoch = 277, Iteration = 0 Total Loss: 0.56112: Recon Loss: 0.42695: Latent Loss: 0.13416: Sparsity Loss: 0.00000: Recon Accuracy: 0.88849\n",
      "Epoch = 278, Iteration = 0 Total Loss: 0.55905: Recon Loss: 0.42573: Latent Loss: 0.13332: Sparsity Loss: 0.00000: Recon Accuracy: 0.88945\n",
      "Epoch = 279, Iteration = 0 Total Loss: 0.55994: Recon Loss: 0.42777: Latent Loss: 0.13217: Sparsity Loss: 0.00000: Recon Accuracy: 0.88979\n",
      "Epoch = 280, Iteration = 0 Total Loss: 0.56072: Recon Loss: 0.42845: Latent Loss: 0.13227: Sparsity Loss: 0.00000: Recon Accuracy: 0.88903\n",
      "Epoch = 281, Iteration = 0 Total Loss: 0.55651: Recon Loss: 0.42407: Latent Loss: 0.13244: Sparsity Loss: 0.00000: Recon Accuracy: 0.88898\n",
      "Epoch = 282, Iteration = 0 Total Loss: 0.55508: Recon Loss: 0.42159: Latent Loss: 0.13349: Sparsity Loss: 0.00000: Recon Accuracy: 0.89013\n",
      "Epoch = 283, Iteration = 0 Total Loss: 0.55565: Recon Loss: 0.42227: Latent Loss: 0.13338: Sparsity Loss: 0.00000: Recon Accuracy: 0.88982\n",
      "Epoch = 284, Iteration = 0 Total Loss: 0.55180: Recon Loss: 0.41969: Latent Loss: 0.13211: Sparsity Loss: 0.00000: Recon Accuracy: 0.89096\n",
      "Epoch = 285, Iteration = 0 Total Loss: 0.55296: Recon Loss: 0.42149: Latent Loss: 0.13147: Sparsity Loss: 0.00000: Recon Accuracy: 0.89019\n",
      "Epoch = 286, Iteration = 0 Total Loss: 0.55200: Recon Loss: 0.42028: Latent Loss: 0.13171: Sparsity Loss: 0.00000: Recon Accuracy: 0.89036\n",
      "Epoch = 287, Iteration = 0 Total Loss: 0.55504: Recon Loss: 0.42294: Latent Loss: 0.13210: Sparsity Loss: 0.00000: Recon Accuracy: 0.89053\n",
      "Epoch = 288, Iteration = 0 Total Loss: 0.55707: Recon Loss: 0.42528: Latent Loss: 0.13178: Sparsity Loss: 0.00000: Recon Accuracy: 0.89038\n",
      "Epoch = 289, Iteration = 0 Total Loss: 0.54969: Recon Loss: 0.41870: Latent Loss: 0.13099: Sparsity Loss: 0.00000: Recon Accuracy: 0.89098\n",
      "Epoch = 290, Iteration = 0 Total Loss: 0.55184: Recon Loss: 0.42108: Latent Loss: 0.13076: Sparsity Loss: 0.00000: Recon Accuracy: 0.89087\n",
      "Epoch = 291, Iteration = 0 Total Loss: 0.54589: Recon Loss: 0.41427: Latent Loss: 0.13162: Sparsity Loss: 0.00000: Recon Accuracy: 0.89185\n",
      "Epoch = 292, Iteration = 0 Total Loss: 0.54991: Recon Loss: 0.41753: Latent Loss: 0.13237: Sparsity Loss: 0.00000: Recon Accuracy: 0.89135\n",
      "Epoch = 293, Iteration = 0 Total Loss: 0.55221: Recon Loss: 0.41992: Latent Loss: 0.13229: Sparsity Loss: 0.00000: Recon Accuracy: 0.89185\n",
      "Epoch = 294, Iteration = 0 Total Loss: 0.54736: Recon Loss: 0.41601: Latent Loss: 0.13135: Sparsity Loss: 0.00000: Recon Accuracy: 0.89133\n",
      "Epoch = 295, Iteration = 0 Total Loss: 0.54501: Recon Loss: 0.41433: Latent Loss: 0.13069: Sparsity Loss: 0.00000: Recon Accuracy: 0.89263\n",
      "Epoch = 296, Iteration = 0 Total Loss: 0.54891: Recon Loss: 0.41825: Latent Loss: 0.13066: Sparsity Loss: 0.00000: Recon Accuracy: 0.89197\n",
      "Epoch = 297, Iteration = 0 Total Loss: 0.54960: Recon Loss: 0.41809: Latent Loss: 0.13151: Sparsity Loss: 0.00000: Recon Accuracy: 0.89194\n",
      "Epoch = 298, Iteration = 0 Total Loss: 0.54647: Recon Loss: 0.41567: Latent Loss: 0.13080: Sparsity Loss: 0.00000: Recon Accuracy: 0.89273\n",
      "Epoch = 299, Iteration = 0 Total Loss: 0.54619: Recon Loss: 0.41616: Latent Loss: 0.13003: Sparsity Loss: 0.00000: Recon Accuracy: 0.89192\n",
      "Epoch = 300, Iteration = 0 Total Loss: 0.54478: Recon Loss: 0.41425: Latent Loss: 0.13053: Sparsity Loss: 0.00000: Recon Accuracy: 0.89248\n",
      "Epoch = 301, Iteration = 0 Total Loss: 0.54935: Recon Loss: 0.41776: Latent Loss: 0.13159: Sparsity Loss: 0.00000: Recon Accuracy: 0.89191\n",
      "Epoch = 302, Iteration = 0 Total Loss: 0.54892: Recon Loss: 0.41683: Latent Loss: 0.13209: Sparsity Loss: 0.00000: Recon Accuracy: 0.89235\n",
      "Epoch = 303, Iteration = 0 Total Loss: 0.54944: Recon Loss: 0.41842: Latent Loss: 0.13101: Sparsity Loss: 0.00000: Recon Accuracy: 0.89235\n",
      "Epoch = 304, Iteration = 0 Total Loss: 0.54330: Recon Loss: 0.41276: Latent Loss: 0.13054: Sparsity Loss: 0.00000: Recon Accuracy: 0.89357\n",
      "Epoch = 305, Iteration = 0 Total Loss: 0.53955: Recon Loss: 0.40777: Latent Loss: 0.13178: Sparsity Loss: 0.00000: Recon Accuracy: 0.89392\n",
      "Epoch = 306, Iteration = 0 Total Loss: 0.54372: Recon Loss: 0.41070: Latent Loss: 0.13302: Sparsity Loss: 0.00000: Recon Accuracy: 0.89336\n",
      "Epoch = 307, Iteration = 0 Total Loss: 0.54913: Recon Loss: 0.41663: Latent Loss: 0.13250: Sparsity Loss: 0.00000: Recon Accuracy: 0.89332\n",
      "Epoch = 308, Iteration = 0 Total Loss: 0.53765: Recon Loss: 0.40668: Latent Loss: 0.13097: Sparsity Loss: 0.00000: Recon Accuracy: 0.89370\n",
      "Epoch = 309, Iteration = 0 Total Loss: 0.54154: Recon Loss: 0.41085: Latent Loss: 0.13069: Sparsity Loss: 0.00000: Recon Accuracy: 0.89368\n",
      "Epoch = 310, Iteration = 0 Total Loss: 0.53993: Recon Loss: 0.40871: Latent Loss: 0.13123: Sparsity Loss: 0.00000: Recon Accuracy: 0.89412\n",
      "Epoch = 311, Iteration = 0 Total Loss: 0.54343: Recon Loss: 0.41163: Latent Loss: 0.13180: Sparsity Loss: 0.00000: Recon Accuracy: 0.89318\n",
      "Epoch = 312, Iteration = 0 Total Loss: 0.54946: Recon Loss: 0.41788: Latent Loss: 0.13158: Sparsity Loss: 0.00000: Recon Accuracy: 0.89292\n",
      "Epoch = 313, Iteration = 0 Total Loss: 0.54301: Recon Loss: 0.41226: Latent Loss: 0.13076: Sparsity Loss: 0.00000: Recon Accuracy: 0.89311\n",
      "Epoch = 314, Iteration = 0 Total Loss: 0.53587: Recon Loss: 0.40570: Latent Loss: 0.13017: Sparsity Loss: 0.00000: Recon Accuracy: 0.89400\n",
      "Epoch = 315, Iteration = 0 Total Loss: 0.53683: Recon Loss: 0.40617: Latent Loss: 0.13066: Sparsity Loss: 0.00000: Recon Accuracy: 0.89373\n",
      "Epoch = 316, Iteration = 0 Total Loss: 0.54243: Recon Loss: 0.41184: Latent Loss: 0.13058: Sparsity Loss: 0.00000: Recon Accuracy: 0.89364\n",
      "Epoch = 317, Iteration = 0 Total Loss: 0.53732: Recon Loss: 0.40700: Latent Loss: 0.13032: Sparsity Loss: 0.00000: Recon Accuracy: 0.89378\n",
      "Epoch = 318, Iteration = 0 Total Loss: 0.53662: Recon Loss: 0.40655: Latent Loss: 0.13007: Sparsity Loss: 0.00000: Recon Accuracy: 0.89403\n",
      "Epoch = 319, Iteration = 0 Total Loss: 0.53544: Recon Loss: 0.40466: Latent Loss: 0.13079: Sparsity Loss: 0.00000: Recon Accuracy: 0.89481\n",
      "Epoch = 320, Iteration = 0 Total Loss: 0.53834: Recon Loss: 0.40679: Latent Loss: 0.13154: Sparsity Loss: 0.00000: Recon Accuracy: 0.89449\n",
      "Epoch = 321, Iteration = 0 Total Loss: 0.53171: Recon Loss: 0.40008: Latent Loss: 0.13163: Sparsity Loss: 0.00000: Recon Accuracy: 0.89590\n",
      "Epoch = 322, Iteration = 0 Total Loss: 0.53780: Recon Loss: 0.40676: Latent Loss: 0.13104: Sparsity Loss: 0.00000: Recon Accuracy: 0.89438\n",
      "Epoch = 323, Iteration = 0 Total Loss: 0.53306: Recon Loss: 0.40299: Latent Loss: 0.13008: Sparsity Loss: 0.00000: Recon Accuracy: 0.89589\n",
      "Epoch = 324, Iteration = 0 Total Loss: 0.53308: Recon Loss: 0.40288: Latent Loss: 0.13020: Sparsity Loss: 0.00000: Recon Accuracy: 0.89566\n",
      "Epoch = 325, Iteration = 0 Total Loss: 0.53492: Recon Loss: 0.40477: Latent Loss: 0.13016: Sparsity Loss: 0.00000: Recon Accuracy: 0.89490\n",
      "Epoch = 326, Iteration = 0 Total Loss: 0.53005: Recon Loss: 0.39979: Latent Loss: 0.13026: Sparsity Loss: 0.00000: Recon Accuracy: 0.89606\n",
      "Epoch = 327, Iteration = 0 Total Loss: 0.53168: Recon Loss: 0.40192: Latent Loss: 0.12977: Sparsity Loss: 0.00000: Recon Accuracy: 0.89565\n",
      "Epoch = 328, Iteration = 0 Total Loss: 0.53338: Recon Loss: 0.40465: Latent Loss: 0.12873: Sparsity Loss: 0.00000: Recon Accuracy: 0.89551\n",
      "Epoch = 329, Iteration = 0 Total Loss: 0.53002: Recon Loss: 0.40105: Latent Loss: 0.12897: Sparsity Loss: 0.00000: Recon Accuracy: 0.89579\n",
      "Epoch = 330, Iteration = 0 Total Loss: 0.53095: Recon Loss: 0.40151: Latent Loss: 0.12943: Sparsity Loss: 0.00000: Recon Accuracy: 0.89633\n",
      "Epoch = 331, Iteration = 0 Total Loss: 0.53473: Recon Loss: 0.40561: Latent Loss: 0.12913: Sparsity Loss: 0.00000: Recon Accuracy: 0.89621\n",
      "Epoch = 332, Iteration = 0 Total Loss: 0.53376: Recon Loss: 0.40517: Latent Loss: 0.12859: Sparsity Loss: 0.00000: Recon Accuracy: 0.89570\n",
      "Epoch = 333, Iteration = 0 Total Loss: 0.52522: Recon Loss: 0.39701: Latent Loss: 0.12821: Sparsity Loss: 0.00000: Recon Accuracy: 0.89679\n",
      "Epoch = 334, Iteration = 0 Total Loss: 0.53051: Recon Loss: 0.40198: Latent Loss: 0.12854: Sparsity Loss: 0.00000: Recon Accuracy: 0.89632\n",
      "Epoch = 335, Iteration = 0 Total Loss: 0.52289: Recon Loss: 0.39349: Latent Loss: 0.12940: Sparsity Loss: 0.00000: Recon Accuracy: 0.89732\n",
      "Epoch = 336, Iteration = 0 Total Loss: 0.52618: Recon Loss: 0.39687: Latent Loss: 0.12931: Sparsity Loss: 0.00000: Recon Accuracy: 0.89692\n",
      "Epoch = 337, Iteration = 0 Total Loss: 0.52637: Recon Loss: 0.39791: Latent Loss: 0.12846: Sparsity Loss: 0.00000: Recon Accuracy: 0.89757\n",
      "Epoch = 338, Iteration = 0 Total Loss: 0.52826: Recon Loss: 0.40045: Latent Loss: 0.12781: Sparsity Loss: 0.00000: Recon Accuracy: 0.89606\n",
      "Epoch = 339, Iteration = 0 Total Loss: 0.53108: Recon Loss: 0.40334: Latent Loss: 0.12774: Sparsity Loss: 0.00000: Recon Accuracy: 0.89624\n",
      "Epoch = 340, Iteration = 0 Total Loss: 0.52653: Recon Loss: 0.39833: Latent Loss: 0.12821: Sparsity Loss: 0.00000: Recon Accuracy: 0.89693\n",
      "Epoch = 341, Iteration = 0 Total Loss: 0.53046: Recon Loss: 0.40162: Latent Loss: 0.12884: Sparsity Loss: 0.00000: Recon Accuracy: 0.89682\n",
      "Epoch = 342, Iteration = 0 Total Loss: 0.52279: Recon Loss: 0.39451: Latent Loss: 0.12828: Sparsity Loss: 0.00000: Recon Accuracy: 0.89774\n",
      "Epoch = 343, Iteration = 0 Total Loss: 0.52363: Recon Loss: 0.39573: Latent Loss: 0.12790: Sparsity Loss: 0.00000: Recon Accuracy: 0.89737\n",
      "Epoch = 344, Iteration = 0 Total Loss: 0.52349: Recon Loss: 0.39543: Latent Loss: 0.12806: Sparsity Loss: 0.00000: Recon Accuracy: 0.89733\n",
      "Epoch = 345, Iteration = 0 Total Loss: 0.52289: Recon Loss: 0.39466: Latent Loss: 0.12823: Sparsity Loss: 0.00000: Recon Accuracy: 0.89724\n",
      "Epoch = 346, Iteration = 0 Total Loss: 0.52402: Recon Loss: 0.39585: Latent Loss: 0.12816: Sparsity Loss: 0.00000: Recon Accuracy: 0.89819\n",
      "Epoch = 347, Iteration = 0 Total Loss: 0.52289: Recon Loss: 0.39441: Latent Loss: 0.12848: Sparsity Loss: 0.00000: Recon Accuracy: 0.89832\n",
      "Epoch = 348, Iteration = 0 Total Loss: 0.52495: Recon Loss: 0.39622: Latent Loss: 0.12873: Sparsity Loss: 0.00000: Recon Accuracy: 0.89763\n",
      "Epoch = 349, Iteration = 0 Total Loss: 0.52368: Recon Loss: 0.39499: Latent Loss: 0.12869: Sparsity Loss: 0.00000: Recon Accuracy: 0.89783\n",
      "Epoch = 350, Iteration = 0 Total Loss: 0.51880: Recon Loss: 0.39050: Latent Loss: 0.12830: Sparsity Loss: 0.00000: Recon Accuracy: 0.89868\n",
      "Epoch = 351, Iteration = 0 Total Loss: 0.53087: Recon Loss: 0.40265: Latent Loss: 0.12821: Sparsity Loss: 0.00000: Recon Accuracy: 0.89741\n",
      "Epoch = 352, Iteration = 0 Total Loss: 0.51777: Recon Loss: 0.38964: Latent Loss: 0.12814: Sparsity Loss: 0.00000: Recon Accuracy: 0.89883\n",
      "Epoch = 353, Iteration = 0 Total Loss: 0.51912: Recon Loss: 0.39128: Latent Loss: 0.12784: Sparsity Loss: 0.00000: Recon Accuracy: 0.89821\n",
      "Epoch = 354, Iteration = 0 Total Loss: 0.51791: Recon Loss: 0.38983: Latent Loss: 0.12808: Sparsity Loss: 0.00000: Recon Accuracy: 0.89873\n",
      "Epoch = 355, Iteration = 0 Total Loss: 0.51866: Recon Loss: 0.39062: Latent Loss: 0.12804: Sparsity Loss: 0.00000: Recon Accuracy: 0.89817\n",
      "Epoch = 356, Iteration = 0 Total Loss: 0.51657: Recon Loss: 0.38847: Latent Loss: 0.12810: Sparsity Loss: 0.00000: Recon Accuracy: 0.89937\n",
      "Epoch = 357, Iteration = 0 Total Loss: 0.51174: Recon Loss: 0.38413: Latent Loss: 0.12761: Sparsity Loss: 0.00000: Recon Accuracy: 0.89956\n",
      "Epoch = 358, Iteration = 0 Total Loss: 0.51860: Recon Loss: 0.39125: Latent Loss: 0.12734: Sparsity Loss: 0.00000: Recon Accuracy: 0.89815\n",
      "Epoch = 359, Iteration = 0 Total Loss: 0.51259: Recon Loss: 0.38543: Latent Loss: 0.12716: Sparsity Loss: 0.00000: Recon Accuracy: 0.89962\n",
      "Epoch = 360, Iteration = 0 Total Loss: 0.51447: Recon Loss: 0.38734: Latent Loss: 0.12713: Sparsity Loss: 0.00000: Recon Accuracy: 0.89970\n",
      "Epoch = 361, Iteration = 0 Total Loss: 0.52161: Recon Loss: 0.39488: Latent Loss: 0.12674: Sparsity Loss: 0.00000: Recon Accuracy: 0.89795\n",
      "Epoch = 362, Iteration = 0 Total Loss: 0.51418: Recon Loss: 0.38848: Latent Loss: 0.12570: Sparsity Loss: 0.00000: Recon Accuracy: 0.89963\n",
      "Epoch = 363, Iteration = 0 Total Loss: 0.51437: Recon Loss: 0.38905: Latent Loss: 0.12532: Sparsity Loss: 0.00000: Recon Accuracy: 0.89896\n",
      "Epoch = 364, Iteration = 0 Total Loss: 0.51323: Recon Loss: 0.38767: Latent Loss: 0.12556: Sparsity Loss: 0.00000: Recon Accuracy: 0.89903\n",
      "Epoch = 365, Iteration = 0 Total Loss: 0.51795: Recon Loss: 0.39219: Latent Loss: 0.12576: Sparsity Loss: 0.00000: Recon Accuracy: 0.89839\n",
      "Epoch = 366, Iteration = 0 Total Loss: 0.51367: Recon Loss: 0.38837: Latent Loss: 0.12530: Sparsity Loss: 0.00000: Recon Accuracy: 0.89884\n",
      "Epoch = 367, Iteration = 0 Total Loss: 0.51565: Recon Loss: 0.39111: Latent Loss: 0.12454: Sparsity Loss: 0.00000: Recon Accuracy: 0.89892\n",
      "Epoch = 368, Iteration = 0 Total Loss: 0.51434: Recon Loss: 0.39016: Latent Loss: 0.12417: Sparsity Loss: 0.00000: Recon Accuracy: 0.89900\n",
      "Epoch = 369, Iteration = 0 Total Loss: 0.51775: Recon Loss: 0.39317: Latent Loss: 0.12458: Sparsity Loss: 0.00000: Recon Accuracy: 0.89893\n",
      "Epoch = 370, Iteration = 0 Total Loss: 0.51739: Recon Loss: 0.39196: Latent Loss: 0.12543: Sparsity Loss: 0.00000: Recon Accuracy: 0.89915\n",
      "Epoch = 371, Iteration = 0 Total Loss: 0.51239: Recon Loss: 0.38668: Latent Loss: 0.12571: Sparsity Loss: 0.00000: Recon Accuracy: 0.90007\n",
      "Epoch = 372, Iteration = 0 Total Loss: 0.51474: Recon Loss: 0.38948: Latent Loss: 0.12526: Sparsity Loss: 0.00000: Recon Accuracy: 0.89891\n",
      "Epoch = 373, Iteration = 0 Total Loss: 0.51279: Recon Loss: 0.38808: Latent Loss: 0.12471: Sparsity Loss: 0.00000: Recon Accuracy: 0.90009\n",
      "Epoch = 374, Iteration = 0 Total Loss: 0.51025: Recon Loss: 0.38553: Latent Loss: 0.12472: Sparsity Loss: 0.00000: Recon Accuracy: 0.89934\n",
      "Epoch = 375, Iteration = 0 Total Loss: 0.51811: Recon Loss: 0.39297: Latent Loss: 0.12515: Sparsity Loss: 0.00000: Recon Accuracy: 0.89889\n",
      "Epoch = 376, Iteration = 0 Total Loss: 0.50701: Recon Loss: 0.38171: Latent Loss: 0.12530: Sparsity Loss: 0.00000: Recon Accuracy: 0.90028\n",
      "Epoch = 377, Iteration = 0 Total Loss: 0.51006: Recon Loss: 0.38508: Latent Loss: 0.12498: Sparsity Loss: 0.00000: Recon Accuracy: 0.89960\n",
      "Epoch = 378, Iteration = 0 Total Loss: 0.50779: Recon Loss: 0.38291: Latent Loss: 0.12488: Sparsity Loss: 0.00000: Recon Accuracy: 0.90058\n",
      "Epoch = 379, Iteration = 0 Total Loss: 0.51141: Recon Loss: 0.38638: Latent Loss: 0.12504: Sparsity Loss: 0.00000: Recon Accuracy: 0.89957\n",
      "Epoch = 380, Iteration = 0 Total Loss: 0.50821: Recon Loss: 0.38251: Latent Loss: 0.12570: Sparsity Loss: 0.00000: Recon Accuracy: 0.90054\n",
      "Epoch = 381, Iteration = 0 Total Loss: 0.51650: Recon Loss: 0.39003: Latent Loss: 0.12647: Sparsity Loss: 0.00000: Recon Accuracy: 0.90044\n",
      "Epoch = 382, Iteration = 0 Total Loss: 0.50880: Recon Loss: 0.38230: Latent Loss: 0.12650: Sparsity Loss: 0.00000: Recon Accuracy: 0.90097\n",
      "Epoch = 383, Iteration = 0 Total Loss: 0.50933: Recon Loss: 0.38312: Latent Loss: 0.12621: Sparsity Loss: 0.00000: Recon Accuracy: 0.90098\n",
      "Epoch = 384, Iteration = 0 Total Loss: 0.50984: Recon Loss: 0.38386: Latent Loss: 0.12598: Sparsity Loss: 0.00000: Recon Accuracy: 0.90006\n",
      "Epoch = 385, Iteration = 0 Total Loss: 0.51222: Recon Loss: 0.38607: Latent Loss: 0.12615: Sparsity Loss: 0.00000: Recon Accuracy: 0.90062\n",
      "Epoch = 386, Iteration = 0 Total Loss: 0.50532: Recon Loss: 0.37861: Latent Loss: 0.12671: Sparsity Loss: 0.00000: Recon Accuracy: 0.90097\n",
      "Epoch = 387, Iteration = 0 Total Loss: 0.51171: Recon Loss: 0.38490: Latent Loss: 0.12681: Sparsity Loss: 0.00000: Recon Accuracy: 0.90056\n",
      "Epoch = 388, Iteration = 0 Total Loss: 0.50370: Recon Loss: 0.37689: Latent Loss: 0.12680: Sparsity Loss: 0.00000: Recon Accuracy: 0.90101\n",
      "Epoch = 389, Iteration = 0 Total Loss: 0.50605: Recon Loss: 0.37957: Latent Loss: 0.12648: Sparsity Loss: 0.00000: Recon Accuracy: 0.90137\n",
      "Epoch = 390, Iteration = 0 Total Loss: 0.50585: Recon Loss: 0.37983: Latent Loss: 0.12601: Sparsity Loss: 0.00000: Recon Accuracy: 0.90098\n",
      "Epoch = 391, Iteration = 0 Total Loss: 0.50717: Recon Loss: 0.38149: Latent Loss: 0.12568: Sparsity Loss: 0.00000: Recon Accuracy: 0.90057\n",
      "Epoch = 392, Iteration = 0 Total Loss: 0.50489: Recon Loss: 0.37896: Latent Loss: 0.12593: Sparsity Loss: 0.00000: Recon Accuracy: 0.90117\n",
      "Epoch = 393, Iteration = 0 Total Loss: 0.50927: Recon Loss: 0.38284: Latent Loss: 0.12643: Sparsity Loss: 0.00000: Recon Accuracy: 0.90035\n",
      "Epoch = 394, Iteration = 0 Total Loss: 0.50439: Recon Loss: 0.37772: Latent Loss: 0.12667: Sparsity Loss: 0.00000: Recon Accuracy: 0.90129\n",
      "Epoch = 395, Iteration = 0 Total Loss: 0.50054: Recon Loss: 0.37455: Latent Loss: 0.12599: Sparsity Loss: 0.00000: Recon Accuracy: 0.90188\n",
      "Epoch = 396, Iteration = 0 Total Loss: 0.50349: Recon Loss: 0.37855: Latent Loss: 0.12495: Sparsity Loss: 0.00000: Recon Accuracy: 0.90123\n",
      "Epoch = 397, Iteration = 0 Total Loss: 0.50443: Recon Loss: 0.38042: Latent Loss: 0.12401: Sparsity Loss: 0.00000: Recon Accuracy: 0.90143\n",
      "Epoch = 398, Iteration = 0 Total Loss: 0.50351: Recon Loss: 0.37984: Latent Loss: 0.12367: Sparsity Loss: 0.00000: Recon Accuracy: 0.90126\n",
      "Epoch = 399, Iteration = 0 Total Loss: 0.50671: Recon Loss: 0.38270: Latent Loss: 0.12400: Sparsity Loss: 0.00000: Recon Accuracy: 0.90078\n",
      "Epoch = 400, Iteration = 0 Total Loss: 0.50721: Recon Loss: 0.38294: Latent Loss: 0.12427: Sparsity Loss: 0.00000: Recon Accuracy: 0.90085\n",
      "Epoch = 401, Iteration = 0 Total Loss: 0.50249: Recon Loss: 0.37814: Latent Loss: 0.12434: Sparsity Loss: 0.00000: Recon Accuracy: 0.90140\n",
      "Epoch = 402, Iteration = 0 Total Loss: 0.50268: Recon Loss: 0.37866: Latent Loss: 0.12402: Sparsity Loss: 0.00000: Recon Accuracy: 0.90094\n",
      "Epoch = 403, Iteration = 0 Total Loss: 0.50787: Recon Loss: 0.38401: Latent Loss: 0.12387: Sparsity Loss: 0.00000: Recon Accuracy: 0.90099\n",
      "Epoch = 404, Iteration = 0 Total Loss: 0.50586: Recon Loss: 0.38155: Latent Loss: 0.12431: Sparsity Loss: 0.00000: Recon Accuracy: 0.90111\n",
      "Epoch = 405, Iteration = 0 Total Loss: 0.50441: Recon Loss: 0.37921: Latent Loss: 0.12520: Sparsity Loss: 0.00000: Recon Accuracy: 0.90132\n",
      "Epoch = 406, Iteration = 0 Total Loss: 0.50809: Recon Loss: 0.38278: Latent Loss: 0.12531: Sparsity Loss: 0.00000: Recon Accuracy: 0.90181\n",
      "Epoch = 407, Iteration = 0 Total Loss: 0.49714: Recon Loss: 0.37181: Latent Loss: 0.12533: Sparsity Loss: 0.00000: Recon Accuracy: 0.90233\n",
      "Epoch = 408, Iteration = 0 Total Loss: 0.50348: Recon Loss: 0.37818: Latent Loss: 0.12531: Sparsity Loss: 0.00000: Recon Accuracy: 0.90176\n",
      "Epoch = 409, Iteration = 0 Total Loss: 0.50443: Recon Loss: 0.37938: Latent Loss: 0.12505: Sparsity Loss: 0.00000: Recon Accuracy: 0.90142\n",
      "Epoch = 410, Iteration = 0 Total Loss: 0.49955: Recon Loss: 0.37490: Latent Loss: 0.12466: Sparsity Loss: 0.00000: Recon Accuracy: 0.90198\n",
      "Epoch = 411, Iteration = 0 Total Loss: 0.50410: Recon Loss: 0.37911: Latent Loss: 0.12498: Sparsity Loss: 0.00000: Recon Accuracy: 0.90178\n",
      "Epoch = 412, Iteration = 0 Total Loss: 0.50508: Recon Loss: 0.38006: Latent Loss: 0.12502: Sparsity Loss: 0.00000: Recon Accuracy: 0.90139\n",
      "Epoch = 413, Iteration = 0 Total Loss: 0.50086: Recon Loss: 0.37636: Latent Loss: 0.12449: Sparsity Loss: 0.00000: Recon Accuracy: 0.90208\n",
      "Epoch = 414, Iteration = 0 Total Loss: 0.50231: Recon Loss: 0.37803: Latent Loss: 0.12428: Sparsity Loss: 0.00000: Recon Accuracy: 0.90160\n",
      "Epoch = 415, Iteration = 0 Total Loss: 0.49797: Recon Loss: 0.37374: Latent Loss: 0.12424: Sparsity Loss: 0.00000: Recon Accuracy: 0.90260\n",
      "Epoch = 416, Iteration = 0 Total Loss: 0.49540: Recon Loss: 0.37107: Latent Loss: 0.12433: Sparsity Loss: 0.00000: Recon Accuracy: 0.90284\n",
      "Epoch = 417, Iteration = 0 Total Loss: 0.50527: Recon Loss: 0.38100: Latent Loss: 0.12427: Sparsity Loss: 0.00000: Recon Accuracy: 0.90216\n",
      "Epoch = 418, Iteration = 0 Total Loss: 0.49673: Recon Loss: 0.37263: Latent Loss: 0.12410: Sparsity Loss: 0.00000: Recon Accuracy: 0.90222\n",
      "Epoch = 419, Iteration = 0 Total Loss: 0.49758: Recon Loss: 0.37384: Latent Loss: 0.12375: Sparsity Loss: 0.00000: Recon Accuracy: 0.90196\n",
      "Epoch = 420, Iteration = 0 Total Loss: 0.49706: Recon Loss: 0.37328: Latent Loss: 0.12378: Sparsity Loss: 0.00000: Recon Accuracy: 0.90295\n",
      "Epoch = 421, Iteration = 0 Total Loss: 0.49962: Recon Loss: 0.37542: Latent Loss: 0.12420: Sparsity Loss: 0.00000: Recon Accuracy: 0.90252\n",
      "Epoch = 422, Iteration = 0 Total Loss: 0.50353: Recon Loss: 0.37893: Latent Loss: 0.12460: Sparsity Loss: 0.00000: Recon Accuracy: 0.90226\n",
      "Epoch = 423, Iteration = 0 Total Loss: 0.49452: Recon Loss: 0.36991: Latent Loss: 0.12460: Sparsity Loss: 0.00000: Recon Accuracy: 0.90319\n",
      "Epoch = 424, Iteration = 0 Total Loss: 0.50341: Recon Loss: 0.37871: Latent Loss: 0.12470: Sparsity Loss: 0.00000: Recon Accuracy: 0.90146\n",
      "Epoch = 425, Iteration = 0 Total Loss: 0.49308: Recon Loss: 0.36828: Latent Loss: 0.12480: Sparsity Loss: 0.00000: Recon Accuracy: 0.90343\n",
      "Epoch = 426, Iteration = 0 Total Loss: 0.49960: Recon Loss: 0.37474: Latent Loss: 0.12487: Sparsity Loss: 0.00000: Recon Accuracy: 0.90296\n",
      "Epoch = 427, Iteration = 0 Total Loss: 0.49401: Recon Loss: 0.36897: Latent Loss: 0.12503: Sparsity Loss: 0.00000: Recon Accuracy: 0.90349\n",
      "Epoch = 428, Iteration = 0 Total Loss: 0.49614: Recon Loss: 0.37102: Latent Loss: 0.12512: Sparsity Loss: 0.00000: Recon Accuracy: 0.90313\n",
      "Epoch = 429, Iteration = 0 Total Loss: 0.49745: Recon Loss: 0.37252: Latent Loss: 0.12493: Sparsity Loss: 0.00000: Recon Accuracy: 0.90295\n",
      "Epoch = 430, Iteration = 0 Total Loss: 0.49550: Recon Loss: 0.37095: Latent Loss: 0.12455: Sparsity Loss: 0.00000: Recon Accuracy: 0.90330\n",
      "Epoch = 431, Iteration = 0 Total Loss: 0.49331: Recon Loss: 0.36925: Latent Loss: 0.12407: Sparsity Loss: 0.00000: Recon Accuracy: 0.90327\n",
      "Epoch = 432, Iteration = 0 Total Loss: 0.49284: Recon Loss: 0.36924: Latent Loss: 0.12359: Sparsity Loss: 0.00000: Recon Accuracy: 0.90384\n",
      "Epoch = 433, Iteration = 0 Total Loss: 0.49370: Recon Loss: 0.37061: Latent Loss: 0.12309: Sparsity Loss: 0.00000: Recon Accuracy: 0.90326\n",
      "Epoch = 434, Iteration = 0 Total Loss: 0.50001: Recon Loss: 0.37675: Latent Loss: 0.12326: Sparsity Loss: 0.00000: Recon Accuracy: 0.90257\n",
      "Epoch = 435, Iteration = 0 Total Loss: 0.49718: Recon Loss: 0.37338: Latent Loss: 0.12380: Sparsity Loss: 0.00000: Recon Accuracy: 0.90269\n",
      "Epoch = 436, Iteration = 0 Total Loss: 0.48806: Recon Loss: 0.36438: Latent Loss: 0.12368: Sparsity Loss: 0.00000: Recon Accuracy: 0.90424\n",
      "Epoch = 437, Iteration = 0 Total Loss: 0.49684: Recon Loss: 0.37342: Latent Loss: 0.12342: Sparsity Loss: 0.00000: Recon Accuracy: 0.90322\n",
      "Epoch = 438, Iteration = 0 Total Loss: 0.49495: Recon Loss: 0.37179: Latent Loss: 0.12316: Sparsity Loss: 0.00000: Recon Accuracy: 0.90364\n",
      "Epoch = 439, Iteration = 0 Total Loss: 0.50129: Recon Loss: 0.37778: Latent Loss: 0.12351: Sparsity Loss: 0.00000: Recon Accuracy: 0.90236\n",
      "Epoch = 440, Iteration = 0 Total Loss: 0.49159: Recon Loss: 0.36789: Latent Loss: 0.12370: Sparsity Loss: 0.00000: Recon Accuracy: 0.90372\n",
      "Epoch = 441, Iteration = 0 Total Loss: 0.49734: Recon Loss: 0.37360: Latent Loss: 0.12374: Sparsity Loss: 0.00000: Recon Accuracy: 0.90351\n",
      "Epoch = 442, Iteration = 0 Total Loss: 0.49883: Recon Loss: 0.37504: Latent Loss: 0.12379: Sparsity Loss: 0.00000: Recon Accuracy: 0.90334\n",
      "Epoch = 443, Iteration = 0 Total Loss: 0.49839: Recon Loss: 0.37484: Latent Loss: 0.12355: Sparsity Loss: 0.00000: Recon Accuracy: 0.90300\n",
      "Epoch = 444, Iteration = 0 Total Loss: 0.49747: Recon Loss: 0.37358: Latent Loss: 0.12389: Sparsity Loss: 0.00000: Recon Accuracy: 0.90296\n",
      "Reconstruction Accuracy: 0.90317\n",
      "INFO:tensorflow:Tutorial\\models\\model_0\\model.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "from DeepTCR.DeepTCR import DeepTCR_U\n",
    "import sys\n",
    "sys.path.append('./DeepTCR-master/')\n",
    "# Instantiate training object\n",
    "DTCRU = DeepTCR_U('Tutorial')\n",
    "\n",
    "#Load Data from directories\n",
    "DTCRU.Get_Data(directory='./data_deeptcr_small',Load_Prev_Data=False,aggregate_by_aa=True,\n",
    "               aa_column_beta=0,count_column=3,v_beta_column=1,j_beta_column=2)\n",
    "\n",
    "#Train VAE\n",
    "DTCRU.Train_VAE(stop_criterion=0.01,Load_Prev_Data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Tutorial\\models\\model_0\\model.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "DTCRU.Train_VAE(Load_Prev_Data=False,sparsity_alpha=1.0,var_explained = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1577de6e220>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(DTCRU.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x157632c4400>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.cumsum(DTCRU.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
